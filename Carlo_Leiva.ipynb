{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlROp950rDLkuk8luLsL7Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vidacelinda/DataMining_PCA-KPCA/blob/main/Carlo_Leiva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Library needed\n",
        "Part 1.1"
      ],
      "metadata": {
        "id": "3pfXiyugcJVS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "adIkJ9pMIsp2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "# from sklearn.decomposition import KernalPCA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PCA\n",
        "Part 1.1"
      ],
      "metadata": {
        "id": "Xwj4ClmsJkzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pca function\n",
        "# from numpy import einsum\n",
        "def my_pca(Data,k):\n",
        "  #calculate mean of the input along each col(featuere)\n",
        "  mean1=np.mean(Data,axis=0)\n",
        "\n",
        "  #center data\n",
        "  D1=Data-mean1\n",
        "\n",
        "  #covaraince matrix of centered data\n",
        "  cov=np.cov(D1,rowvar=False)\n",
        "\n",
        "  #eigenvalues and eigenvectors of covaraince matrix\n",
        "  eigenvalues,eigenvectors=np.linalg.eig(cov)\n",
        "\n",
        "  #sort eigenvalues in descending order and rearrange those eigenvectors\n",
        "  idx=np.argsort(eigenvalues)[::-1]\n",
        "  eigenvalues=eigenvalues[idx]\n",
        "  eigenvectors=eigenvectors[:,idx]\n",
        "\n",
        "  #select top eigenvectors and reduce the dimensionalty\n",
        "  reduced_eigenvectors=eigenvectors[:,:k]\n",
        "\n",
        "  #project the centered data to the reduced eignvectors\n",
        "  projecteddata=np.dot(D1,reduced_eigenvectors)\n",
        "\n",
        "  return projecteddata,reduced_eigenvectors,mean1"
      ],
      "metadata": {
        "id": "SFY_JqfrJmpR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clasification\n",
        "Part 1.1"
      ],
      "metadata": {
        "id": "V6Km_ydEKBYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the distance between two points\n",
        "def dis(x1,x2):\n",
        "  return np.linalg.norm(x1-x2)\n",
        "\n",
        "#classification\n",
        "def myclassifier(Train,Trainlabel,Test):\n",
        "  pred=[]\n",
        "  for testpoint in Test:\n",
        "    pred_dis=[]\n",
        "    for trainpoint in Train:\n",
        "      pred_dis.append(dis(testpoint,trainpoint))\n",
        "    pred.append(Trainlabel[np.argmin(pred_dis)])\n",
        "  return np.array(pred)"
      ],
      "metadata": {
        "id": "iisQwhj5J9fI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculate accuracy\n",
        "Part 1.1"
      ],
      "metadata": {
        "id": "XJrk7_AwJrgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(true_labels,predicted_labels):\n",
        "  if len(true_labels)!=len(predicted_labels):\n",
        "    raise ValueError(\"Length of true_label must be the same.\")\n",
        "  #count the number of correct predictions\n",
        "  correct_predictions=sum(1 for true, predicted in zip(true_labels,predicted_labels)if true == predicted)\n",
        "  #calculate accuracy as the ratio of correct predictions to total predictions\n",
        "  accuracy=correct_predictions / len(true_labels)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "aPp1qhSfJucW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Read Files\n",
        "Part 1.1 (Results)"
      ],
      "metadata": {
        "id": "K2FJ0JwSJySi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read data\n",
        "Traindata=pd.read_csv('TrainData.csv')\n",
        "TestData=pd.read_csv('TestData.csv')\n",
        "\n",
        "Trainlabel=Traindata.iloc[:,-1]#out of all select last col\n",
        "Testlabel=TestData.iloc[:,-1]\n",
        "\n",
        "label1=Trainlabel.to_numpy()# classifier\n",
        "label2=Testlabel.to_numpy()#added accuracy\n",
        "\n",
        "Trainx=Traindata.iloc[::-1]#select all and start from back to front col\n",
        "Testx=TestData.iloc[::-1]\n",
        "\n",
        "Train=Trainx.to_numpy()\n",
        "Test=Testx.to_numpy()\n",
        "\n",
        "# label1=Trainlabel.to_numpy()\n",
        "# label2=Testlabel.to_numpy()\n",
        "\n",
        "# print(Train)\n",
        "#*** STOP AND CHECK\n",
        "#apply pca to train data\n",
        "k = 110\n",
        "project_train,reduced_eigenvectors,mean1=my_pca(Train,k) #CHECK AND DOWN ASWELL\n",
        "#apply my_pca for\n",
        "Test_centered=Test-mean1\n",
        "projected_test=np.dot(Test_centered,reduced_eigenvectors)#\n",
        "#apply classifier on my_pca\n",
        "predict_label=myclassifier(project_train,label1,projected_test)\n",
        "accuracy=calculate_accuracy(label2,predict_label)\n",
        "\n",
        "percnetage_accuracy=accuracy*100\n",
        "print(f\"my PCA accuracy percentage {percnetage_accuracy:.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agkezAIRJxUy",
        "outputId": "b9dec377-f62f-4494-de09-25c9d9be370f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my PCA accuracy percentage 88.50 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sklearn PCA\n",
        "Part 1.2 (Results)"
      ],
      "metadata": {
        "id": "Pto5kj0yVhXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Read the data\n",
        "Traindata = pd.read_csv('TrainData.csv')\n",
        "TestData = pd.read_csv('TestData.csv')\n",
        "\n",
        "# Extract features and labels\n",
        "TrainX = Traindata.iloc[:, :-1].values\n",
        "Trainy = Traindata.iloc[:, -1].values\n",
        "\n",
        "TestX = TestData.iloc[:, :-1].values\n",
        "Testy = TestData.iloc[:, -1].values\n",
        "\n",
        "# sklearn PCA on the training data\n",
        "pca = PCA(n_components=110)\n",
        "project_train = pca.fit_transform(TrainX)\n",
        "\n",
        "# Apply PCA on the test data\n",
        "projected_test = pca.transform(TestX)\n",
        "\n",
        "# Train a classifier (Logistic Regression)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(project_train, Trainy)\n",
        "\n",
        "# Predict using the transformed testing data\n",
        "predicted_labels = classifier.predict(projected_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(Testy, predicted_labels)\n",
        "percentage_accuracy = accuracy * 100\n",
        "print(f\"Sklearn PCA Accuracy percentage: {percentage_accuracy:.2f} %\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPVUSYBDXNko",
        "outputId": "48c56614-3e30-483a-ef4d-90a621dd9d60"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn PCA Accuracy percentage: 90.50 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KPCA RBF : Scratch\n",
        "part 2.1 and 3.1"
      ],
      "metadata": {
        "id": "Ef5e5iVJuYAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def rbf_kernel(X, sigma=1.0):\n",
        "\n",
        "    #RBF (Gaussian) kernel matrix.\n",
        "    #X (numpy array): Input data matrix of shape (m, n), where m is the number of samples and n is the number of features.\n",
        "    #sigma (float): Width parameter for the RBF kernel.\"\"\"\n",
        "    m = X.shape[0]\n",
        "    K = np.zeros((m, m))\n",
        "    for i in range(m):\n",
        "        for j in range(m):\n",
        "            K[i, j] = np.exp(-np.linalg.norm(X[i] - X[j]) ** 2 / (2 * sigma ** 2))\n",
        "\n",
        "    # K (numpy array): RBF kernel matrix of shape (m, m).\n",
        "    return K\n",
        "\n",
        "def center_kernel_matrix(K):\n",
        "    \"\"\"\n",
        "    Centers the kernel matrix.\n",
        "\n",
        "    Parameters:\n",
        "    K (numpy array): Input kernel matrix.\n",
        "\n",
        "    Returns:\n",
        "    K_centered (numpy array): Centered kernel matrix.\n",
        "    \"\"\"\n",
        "    n = K.shape[0]\n",
        "    one_n = np.ones((n, n)) / n\n",
        "    K_centered = K - np.dot(one_n, K) - np.dot(K, one_n) + np.dot(np.dot(one_n, K), one_n)\n",
        "    return K_centered\n",
        "\n",
        "def kernel_pca(X, n_components, kernel='rbf', sigma=1.0):\n",
        "    \"\"\"\n",
        "    Computes Kernel PCA.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy array): Input data matrix of shape (m, n), where m is the number of samples and n is the number of features.\n",
        "    n_components (int): Number of components for the transformed data.\n",
        "    kernel (str): Kernel type ('rbf' for RBF kernel).\n",
        "    sigma (float): Width parameter for the RBF kernel.\n",
        "\n",
        "    Returns:\n",
        "    transformed_data (numpy array): Transformed data matrix of shape (m, n_components).\n",
        "    \"\"\"\n",
        "    if kernel == 'rbf':\n",
        "        K = rbf_kernel(X, sigma)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported kernel type. Use 'rbf' for RBF kernel.\")\n",
        "\n",
        "    K_centered = center_kernel_matrix(K)\n",
        "\n",
        "    # Compute eigenvectors and eigenvalues\n",
        "    eigvals, eigvecs = np.linalg.eig(K_centered)\n",
        "\n",
        "    # Sort eigenvectors by eigenvalues in descending order\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    eigvecs_sorted = eigvecs[:, idx]\n",
        "\n",
        "    # Select top k eigenvectors\n",
        "    transformed_data = eigvecs_sorted[:, :n_components]\n",
        "\n",
        "    return transformed_data\n",
        "\n",
        "# Example usage\n",
        "# training data TrainX\n",
        "# n_components = 110  # Number of components\n",
        "# sigma = 1.0  # RBF kernel parameter\n",
        "# Compute Kernel PCA using RBF kernel\n",
        "# transformed_train_data = kernel_pca(TrainX, n_components, kernel='rbf', sigma=sigma)\n"
      ],
      "metadata": {
        "id": "O7AqeHihtrrd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sklearn_KPCA RBF\n",
        "part 2.1 and 3.1 (Comparing to Scratch work of KPCA RBF I made after this code cell)\n"
      ],
      "metadata": {
        "id": "6I1tMq8KPfZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read the data\n",
        "Traindata = pd.read_csv('TrainData.csv')\n",
        "TestData = pd.read_csv('TestData.csv')\n",
        "\n",
        "# Extract features and labels\n",
        "TrainX = Traindata.iloc[:, :-1].values\n",
        "Trainy = Traindata.iloc[:, -1].values\n",
        "TestX = TestData.iloc[:, :-1].values\n",
        "Testy = TestData.iloc[:, -1].values\n",
        "\n",
        "# sklearn Kernel PCA on the training data with RBF kernel\n",
        "kpca = KernelPCA(kernel='rbf', n_components=110)\n",
        "project_train = kpca.fit_transform(TrainX)\n",
        "\n",
        "# Apply Kernel PCA on the test data\n",
        "projected_test = kpca.transform(TestX)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "project_train_scaled = scaler.fit_transform(project_train)\n",
        "projected_test_scaled = scaler.transform(projected_test)\n",
        "\n",
        "# Train a classifier (Logistic Regression)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(project_train_scaled, Trainy)\n",
        "\n",
        "# Predict using the transformed testing data\n",
        "predicted_labels = classifier.predict(projected_test_scaled)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(Testy, predicted_labels)\n",
        "percentage_accuracy = accuracy * 100\n",
        "print(f\"sklearn KPCA RBF Accuracy percentage: {percentage_accuracy:.2f} %\")"
      ],
      "metadata": {
        "id": "Mokbeee5Pm7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c27910-d23d-4bd9-c254-22597fd82db1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn KPCA RBF Accuracy percentage: 2.50 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KPCA RBF :Scratch\n",
        "part 2.1 and 3.1 - accuracy results"
      ],
      "metadata": {
        "id": "V27Ln0MRvBdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read the data\n",
        "Traindata = pd.read_csv('TrainData.csv')\n",
        "TestData = pd.read_csv('TestData.csv')\n",
        "\n",
        "# Extract features and labels\n",
        "TrainX = Traindata.iloc[:, :-1].values\n",
        "Trainy = Traindata.iloc[:, -1].values\n",
        "TestX = TestData.iloc[:, :-1].values\n",
        "Testy = TestData.iloc[:, -1].values\n",
        "\n",
        "# sklearn Kernel PCA on the training data with RBF kernel\n",
        "kpca = KernelPCA(kernel='rbf', n_components=110)\n",
        "project_train = kpca.fit_transform(TrainX)\n",
        "\n",
        "# Apply Kernel PCA on the test data\n",
        "projected_test = kpca.transform(TestX)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "project_train_scaled = scaler.fit_transform(project_train)\n",
        "projected_test_scaled = scaler.transform(projected_test)\n",
        "\n",
        "# Train a classifier (Logistic Regression)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(project_train_scaled, Trainy)\n",
        "\n",
        "# Predict using the transformed testing data\n",
        "predicted_labels = classifier.predict(projected_test_scaled)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(Testy, predicted_labels)\n",
        "percentage_accuracy = accuracy * 100\n",
        "print(f\"my KPCA RBF Accuracy percentage: {percentage_accuracy:.2f} %\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6F_bESsuJYE",
        "outputId": "17e7f9cb-c577-4a88-a4c3-d21250023c7a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my KPCA RBF Accuracy percentage: 2.50 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KPCA polynomial_kernal form scratch\n",
        "part 2.2 and 3.1 - KPCA polynomial function and accuraccy results."
      ],
      "metadata": {
        "id": "OtFIjYnvxVG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Polynomial Kernel Function\n",
        "def polynomial_kernel(X, Y, degree=3):\n",
        "    return (np.dot(X, Y.T) + 1) ** degree\n",
        "\n",
        "# Center the Kernel Matrix\n",
        "def center_kernel_matrix(K):\n",
        "    n = K.shape[0]\n",
        "    one_n = np.ones((n, n)) / n\n",
        "    K_centered = K - np.dot(one_n, K) - np.dot(K, one_n) + np.dot(np.dot(one_n, K), one_n)\n",
        "    return K_centered\n",
        "\n",
        "# Kernel PCA with Polynomial Kernel\n",
        "def kernel_pca_poly(X, n_components, degree=3):\n",
        "    # Calculate the Polynomial kernel matrix\n",
        "    K = polynomial_kernel(X, X, degree)\n",
        "\n",
        "    # Center the kernel matrix\n",
        "    K_centered = center_kernel_matrix(K)\n",
        "\n",
        "    # Compute eigenvectors and eigenvalues\n",
        "    eigvals, eigvecs = np.linalg.eig(K_centered)\n",
        "\n",
        "    # Sort eigenvectors by eigenvalues in descending order\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    eigvecs_sorted = eigvecs[:, idx]\n",
        "\n",
        "    # Select top k eigenvectors\n",
        "    transformed_data = eigvecs_sorted[:, :n_components]\n",
        "\n",
        "    return transformed_data\n",
        "\n",
        "# Read the data\n",
        "Traindata = pd.read_csv('TrainData.csv')\n",
        "TestData = pd.read_csv('TestData.csv')\n",
        "\n",
        "# Extract features and labels\n",
        "TrainX = Traindata.iloc[:, :-1].values\n",
        "Trainy = Traindata.iloc[:, -1].values\n",
        "TestX = TestData.iloc[:, :-1].values\n",
        "Testy = TestData.iloc[:, -1].values\n",
        "\n",
        "# Kernel PCA with Polynomial kernel\n",
        "n_components = 110  # Number of components\n",
        "degree = 3  # Polynomial degree\n",
        "project_train = kernel_pca_poly(TrainX, n_components, degree)\n",
        "\n",
        "# Apply Kernel PCA on the test data\n",
        "projected_test = kernel_pca_poly(TestX, n_components, degree)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "project_train_scaled = scaler.fit_transform(project_train)\n",
        "projected_test_scaled = scaler.transform(projected_test)\n",
        "\n",
        "# Train a classifier (Logistic Regression)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(project_train_scaled, Trainy)\n",
        "\n",
        "# Predict using the transformed testing data\n",
        "predicted_labels = classifier.predict(projected_test_scaled)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(Testy, predicted_labels)\n",
        "percentage_accuracy = accuracy * 100\n",
        "print(f\"my KPCA Polynomial Accuracy percentage: {percentage_accuracy:.2f} %\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-RcWWF7yBXL",
        "outputId": "82d0e5dc-41cf-4641-c766-6c3c84b77a26"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my KPCA Polynomial Accuracy percentage: 3.50 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sklearn_KPCA polynomial Kernel\n",
        "part 2.2 and 3.1 (using to compare to my Scratch work of my KPCA Polynomial Kernal)"
      ],
      "metadata": {
        "id": "l_sTrvBpwOJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read the data\n",
        "Traindata = pd.read_csv('TrainData.csv')\n",
        "TestData = pd.read_csv('TestData.csv')\n",
        "\n",
        "# Extract features and labels\n",
        "TrainX = Traindata.iloc[:, :-1].values\n",
        "Trainy = Traindata.iloc[:, -1].values\n",
        "TestX = TestData.iloc[:, :-1].values\n",
        "Testy = TestData.iloc[:, -1].values\n",
        "\n",
        "# sklearn Kernel PCA on the training data with Polynomial kernel\n",
        "kpca = KernelPCA(kernel='poly', degree=3, n_components=110)  # Using Polynomial kernel with degree 3\n",
        "project_train = kpca.fit_transform(TrainX)\n",
        "\n",
        "# Apply Kernel PCA on the test data\n",
        "projected_test = kpca.transform(TestX)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "project_train_scaled = scaler.fit_transform(project_train)\n",
        "projected_test_scaled = scaler.transform(projected_test)\n",
        "\n",
        "# Train a classifier (Logistic Regression)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(project_train_scaled, Trainy)\n",
        "\n",
        "# Predict using the transformed testing data\n",
        "predicted_labels = classifier.predict(projected_test_scaled)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(Testy, predicted_labels)\n",
        "percentage_accuracy = accuracy * 100\n",
        "print(f\"sklearn KPCA Polynomial Accuracy percentage: {percentage_accuracy:.2f} %\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwcOnI4awOc4",
        "outputId": "4b09cab0-8465-4c8e-929b-706b12f2f187"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn KPCA Polynomial Accuracy percentage: 87.00 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KPCA linear Kernel : scratch\n",
        "part 2.3"
      ],
      "metadata": {
        "id": "Uiv3P2kexP_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Linear Kernel Function\n",
        "def linear_kernel(X, Y):\n",
        "    return np.dot(X, Y.T)\n",
        "\n",
        "# Center the Kernel Matrix\n",
        "def center_kernel_matrix(K):\n",
        "    n = K.shape[0]\n",
        "    one_n = np.ones((n, n)) / n\n",
        "    K_centered = K - np.dot(one_n, K) - np.dot(K, one_n) + np.dot(np.dot(one_n, K), one_n)\n",
        "    return K_centered\n",
        "\n",
        "# Kernel PCA with Linear Kernel\n",
        "def kernel_pca_linear(X, n_components):\n",
        "    # Calculate the Linear kernel matrix\n",
        "    K = linear_kernel(X, X)\n",
        "\n",
        "    # Center matrix\n",
        "    K_centered = center_kernel_matrix(K)\n",
        "\n",
        "    eigvals, eigvecs = np.linalg.eig(K_centered)\n",
        "\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    eigvecs_sorted = eigvecs[:, idx]\n",
        "\n",
        "    transformed_data = eigvecs_sorted[:, :n_components]\n",
        "\n",
        "    return transformed_data\n",
        "\n",
        "# Read the data\n",
        "Traindata = pd.read_csv('TrainData.csv')\n",
        "\n",
        "# Extract features and labels\n",
        "TrainX = Traindata.iloc[:, :-1].values\n",
        "\n",
        "# Kernel PCA with Linear kernel\n",
        "n_components = 110  # Number of components\n",
        "project_train = kernel_pca_linear(TrainX, n_components)\n",
        "\n",
        "# Print transformed data for verification\n",
        "print(\"Transformed data (first 5 rows):\")\n",
        "print(project_train[:5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGwFZaVSxYGV",
        "outputId": "61f50576-e682-4739-b174-539863d21c2b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data (first 5 rows):\n",
            "[[ 5.50754689e-02 -6.97958885e-02 -1.17073696e-01 -4.59802784e-02\n",
            "  -2.06216876e-02  3.73373512e-02  6.67687532e-02  2.66483643e-02\n",
            "   1.13930946e-01  9.45030937e-02 -3.18857240e-02 -2.21127324e-02\n",
            "   8.91550087e-02  5.78896381e-02 -8.15920971e-02  1.97074325e-02\n",
            "  -1.66449361e-02 -1.41803377e-02 -5.98313433e-03 -1.01776189e-04\n",
            "   1.20531222e-01  5.40112038e-02  7.37194605e-02  3.36698533e-02\n",
            "   7.59870029e-02 -6.23172939e-02 -1.15014118e-01  3.63992653e-02\n",
            "   4.01684074e-02 -1.59510585e-02  4.37717159e-02 -2.95860077e-02\n",
            "   1.10919216e-01 -4.01798298e-02  5.97400664e-02  4.21001899e-02\n",
            "   6.08933910e-02  7.90193925e-03  4.30642705e-02 -1.16818645e-01\n",
            "   8.94703305e-02  5.54122919e-02 -2.71663620e-02 -1.70618795e-02\n",
            "  -2.51822374e-02 -6.80929428e-02 -9.94237568e-02 -7.17446614e-02\n",
            "  -6.27666939e-02 -2.85228594e-02  1.27952045e-01 -3.32198863e-02\n",
            "  -1.03387681e-02  6.03453605e-02  1.62571530e-01  6.32684681e-02\n",
            "  -2.98557830e-02 -4.45079620e-02 -4.51840558e-02  2.17710559e-02\n",
            "  -7.79688446e-02  1.14102178e-01 -7.81338764e-02  4.14574938e-02\n",
            "   8.85698933e-02 -1.70421846e-01  4.41461717e-02 -3.42453209e-02\n",
            "   1.12860846e-03  6.06569486e-02 -9.29929368e-02 -3.95856568e-02\n",
            "   8.61215598e-02  9.27992418e-04 -8.30065633e-02  1.54957369e-01\n",
            "  -2.64552890e-02  1.39029192e-01  2.09918041e-02 -5.99686177e-02\n",
            "   2.35794396e-02 -2.76580111e-02 -4.75676418e-02 -7.86938882e-02\n",
            "  -9.19790494e-02  1.65822261e-01 -6.23532795e-02 -5.46241429e-03\n",
            "   8.57677900e-02  9.15825140e-03 -3.07378453e-02  2.30622047e-03\n",
            "   1.46685062e-01  3.50048399e-02  5.54328727e-02  6.18553567e-02\n",
            "   2.35145516e-02 -8.59980218e-02 -9.60033022e-02  1.10450581e-01\n",
            "   4.17118116e-03 -1.61936938e-01  1.57395331e-03 -3.53288650e-02\n",
            "   6.25904727e-02 -1.92367278e-02  1.82294899e-01 -8.45736714e-02\n",
            "  -5.95076589e-02  1.30449849e-01]\n",
            " [ 1.17382688e-01 -5.61864172e-02  2.05485410e-02 -7.55943489e-03\n",
            "  -2.09388348e-01  2.72360811e-02  1.01869579e-01 -5.79929290e-02\n",
            "   7.20231015e-02 -1.17078050e-02  4.15865602e-02  1.58559217e-02\n",
            "   3.51358185e-02 -1.81627149e-01 -5.54600477e-02 -3.66538516e-02\n",
            "  -8.20581522e-02  2.73338982e-02  2.05212901e-01 -1.10130285e-01\n",
            "   5.64895057e-03  3.53335352e-02  5.02764245e-03  7.21331152e-02\n",
            "   3.22586897e-02  4.52238215e-02 -2.40893199e-03  2.36817832e-02\n",
            "  -1.01204745e-02  1.75073964e-03 -6.25192302e-02  7.24823577e-02\n",
            "  -5.16385490e-02  1.39292436e-01  1.51409906e-01  1.42381549e-01\n",
            "  -3.10039307e-02  8.68643453e-02 -4.03543458e-02 -3.84528706e-02\n",
            "   1.11651870e-01  6.91860738e-02  3.20123259e-02 -6.21568924e-02\n",
            "   2.40372100e-02 -1.23114526e-01 -1.35791577e-01 -3.44976590e-02\n",
            "  -6.70503552e-02 -2.76582389e-02 -1.02676401e-01  6.28422825e-02\n",
            "   5.03951428e-02 -4.33656951e-02  1.21912101e-01  2.33806120e-02\n",
            "   5.46168780e-02 -6.16470381e-03  4.81492421e-02  4.11348510e-02\n",
            "   3.37749946e-02 -1.18203342e-01  1.14922607e-01 -7.36490586e-04\n",
            "  -1.23059417e-01 -1.37932780e-02 -7.93474046e-02  8.95513412e-02\n",
            "  -5.36927122e-02 -6.58532373e-02 -2.12137866e-02  2.79246214e-02\n",
            "  -9.66901708e-02  4.03476834e-02  6.65041179e-02 -8.44331089e-03\n",
            "   6.45835891e-02  7.28455230e-02  1.25338543e-01  5.73949566e-02\n",
            "  -6.83213828e-02  3.55968346e-02 -2.40843240e-02  7.46417540e-02\n",
            "   2.40062158e-02 -2.40833522e-02 -1.09276202e-01 -2.33900753e-02\n",
            "   3.62862269e-02 -1.09591162e-01  8.43893131e-02  1.46912913e-01\n",
            "  -2.39054678e-04  8.94498473e-02  5.82000839e-02  4.19880729e-02\n",
            "   2.35578417e-02 -9.87522425e-02 -8.93545462e-02  1.69209820e-02\n",
            "   7.46676086e-02 -5.85805795e-02 -4.07845544e-03 -8.33783855e-03\n",
            "  -5.27517467e-02 -1.74936651e-02  9.25275000e-02 -1.59735317e-02\n",
            "  -1.39567866e-01  3.21868582e-02]\n",
            " [ 1.03983994e-01 -4.00111617e-02 -5.21305216e-02 -7.19522564e-02\n",
            "  -2.36914724e-02  1.26697554e-01  2.73921499e-02 -1.29579850e-02\n",
            "   1.83996719e-01  4.21164111e-02 -3.35651862e-02 -9.16099239e-02\n",
            "  -2.42654242e-02 -2.30355510e-02 -1.10058985e-01 -6.48144136e-02\n",
            "   2.10225348e-02  7.47330189e-02 -7.03331636e-02 -1.95456956e-02\n",
            "   6.23389231e-02  5.27591873e-02  3.73216646e-02  3.41521290e-02\n",
            "   1.82303555e-02  1.67356189e-02 -1.19666834e-01 -1.17203248e-01\n",
            "   7.62026990e-02 -3.35636575e-02 -7.51722957e-02  1.16804882e-01\n",
            "  -8.66566854e-02 -1.56379813e-01  1.15599293e-01 -2.51657533e-02\n",
            "   3.05649258e-02  5.08491491e-02  1.43532119e-01 -5.09686889e-02\n",
            "   1.50445744e-01 -8.08338377e-02 -7.05841882e-02  3.15080903e-03\n",
            "   1.23330045e-01 -8.74302557e-03 -3.41488943e-02 -8.73485569e-02\n",
            "  -1.61857377e-01  1.17439075e-01 -1.90935282e-02 -1.49620374e-02\n",
            "   6.39268953e-02  7.86714425e-02  1.12488871e-01  2.93856543e-02\n",
            "   6.44962963e-03  6.42231133e-02  8.54932974e-02 -7.96490291e-02\n",
            "   1.07996908e-01 -8.02475604e-02 -1.52505588e-01 -1.80335765e-02\n",
            "   2.09009323e-02  8.56343420e-02  2.71663767e-02 -2.96093712e-02\n",
            "  -4.62662175e-02  1.31153781e-01  4.60740513e-02  4.23143447e-03\n",
            "  -4.91257706e-03  2.40636502e-02  1.00895440e-01  8.44158591e-02\n",
            "   2.06877248e-02 -1.84056808e-02 -1.23632785e-01 -8.29010503e-02\n",
            "  -9.41981238e-02 -1.39501293e-01  4.82160170e-03  3.90628663e-02\n",
            "   9.46012778e-02 -5.08120250e-02 -6.57439404e-02  1.52722991e-02\n",
            "  -3.58407201e-02  1.53265489e-01 -1.42772787e-01 -1.14167304e-02\n",
            "  -2.20963636e-02 -3.11707123e-02 -2.67777507e-02 -3.54999649e-02\n",
            "   2.45057530e-03  1.53538466e-01  2.07893085e-02  5.44745704e-02\n",
            "   1.14170909e-01  1.12138612e-01 -1.32202900e-01  8.00114455e-02\n",
            "   1.55765174e-01 -3.09160460e-02 -1.20988891e-01  4.58332468e-02\n",
            "   1.92018625e-01  8.60077530e-02]\n",
            " [ 1.24931272e-01 -6.96118954e-02 -2.56061395e-02  1.58756281e-01\n",
            "  -6.04804803e-02  1.27795951e-01 -3.93096459e-02  1.00707089e-01\n",
            "   2.08706988e-02  1.96892216e-01 -1.14133583e-01 -4.20901498e-02\n",
            "   1.11201972e-01 -2.72686684e-03  8.75763062e-02  1.13127254e-01\n",
            "   6.16663132e-02  8.45033354e-02 -4.96690870e-02 -1.37505786e-01\n",
            "   3.47864789e-02 -6.14543905e-02 -3.37524826e-03 -1.01939220e-01\n",
            "   1.88880141e-02  6.37960819e-02 -5.75071610e-02 -4.77629000e-02\n",
            "   3.81901936e-02 -2.46286839e-02  2.27778482e-02  7.83241450e-02\n",
            "  -9.09478202e-02 -1.27842063e-01 -1.30094680e-01 -8.15329885e-02\n",
            "  -1.09033581e-01 -4.97758022e-05  9.49396962e-02  2.09993790e-02\n",
            "  -8.45307003e-02 -6.30880629e-02  1.28068094e-03  1.36994304e-02\n",
            "  -2.17887986e-02 -4.02689385e-02 -4.51650383e-02 -5.33113539e-02\n",
            "  -6.53128229e-02  3.77109344e-02  1.26286227e-01 -1.66468069e-02\n",
            "  -2.16825045e-02  9.28687930e-02 -1.58831213e-01 -1.36875160e-01\n",
            "   5.93111140e-02  5.48832376e-02 -4.94409126e-02 -7.37464153e-03\n",
            "   7.71177023e-02  1.38943829e-02 -6.24949801e-02  1.30924109e-02\n",
            "   1.22886547e-02 -3.19459769e-02  7.31734935e-02  8.99658646e-02\n",
            "   4.37514726e-02 -3.45449641e-03  5.72595896e-02 -1.54445384e-02\n",
            "   4.87558718e-02 -1.61846540e-01  4.44717119e-02 -7.87660560e-02\n",
            "   1.28498755e-01  5.54528243e-02 -7.94473328e-03  4.77359476e-02\n",
            "  -8.11223405e-03  2.10784504e-02 -1.40527490e-01  4.55522267e-02\n",
            "   1.12493079e-01 -9.12993711e-03  1.65174350e-02 -1.24427138e-01\n",
            "   1.59940742e-01 -8.76326644e-02 -4.45695294e-02  2.01845986e-01\n",
            "   1.03303736e-01 -5.06282342e-02 -1.09425841e-01  7.78764251e-02\n",
            "  -1.37400715e-01 -8.63886180e-02 -8.35918539e-02 -6.35551570e-03\n",
            "  -3.20250344e-02  4.72598116e-02 -5.70216089e-02  9.95437946e-02\n",
            "  -1.54373652e-02  2.58418401e-02 -3.16872492e-02  1.09683292e-02\n",
            "  -9.71713385e-02 -1.04105429e-01]\n",
            " [ 1.43348888e-01 -6.12244780e-02 -3.62630240e-02  1.14928325e-01\n",
            "  -6.83904648e-02  8.41407728e-02  3.33806637e-02 -3.00717333e-02\n",
            "   3.68229604e-02  3.10568672e-02 -4.58213176e-03 -2.81848819e-02\n",
            "   5.99140193e-02 -1.57184323e-01  1.13115255e-02  4.46096678e-02\n",
            "  -1.84760332e-02  5.02962531e-02  2.29981619e-01 -1.69352734e-01\n",
            "  -6.95668012e-02  6.16896400e-02 -8.96809877e-02  2.44420426e-02\n",
            "   9.87417887e-02  4.28816850e-02 -4.26009748e-02  6.28418027e-02\n",
            "   8.89831874e-02  1.61118346e-02 -7.05081295e-02  9.40913247e-02\n",
            "  -2.02073474e-02  1.18914655e-02  1.21251352e-01  1.00254744e-01\n",
            "  -7.96735010e-02  1.02049442e-01 -1.44965108e-01  3.03886614e-02\n",
            "  -2.65698943e-02  3.37463062e-02  3.45705511e-02  7.56035916e-02\n",
            "  -6.15745141e-02 -1.70451531e-01 -6.78519650e-02  1.77607644e-02\n",
            "  -4.18082219e-02 -7.45582836e-02 -4.50525421e-02  1.02345906e-01\n",
            "   1.58666761e-02 -4.81717588e-02  6.46107129e-02  2.71218979e-02\n",
            "   5.69720634e-02  2.28770515e-02  2.68769512e-02  4.48820090e-02\n",
            "  -2.66542194e-02 -1.61090050e-02  9.75694405e-02  8.00203365e-02\n",
            "   6.78356928e-02  7.36698721e-02 -4.78315689e-02  8.52560473e-02\n",
            "   1.24020809e-02 -4.46938532e-02  1.00528311e-03  1.11247835e-01\n",
            "   3.96932938e-02  4.39236931e-02  3.92425700e-02  9.78905622e-02\n",
            "   4.18652310e-02 -4.49550540e-02  2.63067531e-02  1.27096219e-01\n",
            "  -4.09448250e-02 -6.52308489e-02  4.98663842e-02  9.35849725e-02\n",
            "   3.39788061e-02 -4.07765438e-02 -4.07108278e-02  3.12571851e-02\n",
            "  -4.13805001e-02 -9.73966130e-03  8.25010373e-02 -5.89979768e-02\n",
            "  -9.57320763e-02  3.97967869e-02  1.38501247e-02  5.33338099e-02\n",
            "  -6.17287262e-02 -3.39291532e-02  1.96528405e-02 -1.30507437e-01\n",
            "   6.51425373e-03 -5.15423828e-02  5.09573512e-02 -9.56372171e-02\n",
            "   2.71183830e-02 -5.15166887e-02 -1.57288013e-01  7.93910641e-02\n",
            "   5.67789273e-02  1.59417915e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sklearn KPCA linear Kernel\n",
        "part 2.3"
      ],
      "metadata": {
        "id": "vSNIWJx1xzJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read the data\n",
        "Traindata = pd.read_csv('TrainData.csv')\n",
        "\n",
        "# Extract features and labels\n",
        "TrainX = Traindata.iloc[:, :-1].values\n",
        "\n",
        "# Linear Kernel PCA\n",
        "n_components = 110  # Number of components\n",
        "\n",
        "# Use 'linear' kernel for Linear Kernel PCA\n",
        "kpca = KernelPCA(kernel='linear', n_components=n_components)\n",
        "\n",
        "# Fit and transform the data\n",
        "project_train = kpca.fit_transform(TrainX)\n",
        "\n",
        "# Print transformed data for verification\n",
        "print(\"Transformed data (first 5 rows):\")\n",
        "print(project_train[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Op9_Em-xjtE",
        "outputId": "dd262537-4d67-4308-fcec-1a323f06198c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed data (first 5 rows):\n",
            "[[ 1.36240472e+03 -1.41001500e+03 -1.78687541e+03  6.25406890e+02\n",
            "   2.67726312e+02 -3.88312936e+02 -6.24476326e+02  2.45615803e+02\n",
            "  -9.42942947e+02  7.23005035e+02  2.35515112e+02  1.46874206e+02\n",
            "   5.68975288e+02  3.57358325e+02 -4.84663930e+02  1.12171321e+02\n",
            "  -9.32622614e+01 -7.61817102e+01 -3.07585312e+01  5.06221788e-01\n",
            "   5.95252190e+02  2.54056084e+02 -3.37091649e+02  1.49962460e+02\n",
            "   3.36100793e+02  2.66438238e+02 -4.80516213e+02 -1.50439222e+02\n",
            "   1.63156214e+02 -6.31287313e+01 -1.69148922e+02 -1.10878470e+02\n",
            "  -4.14572743e+02 -1.46873743e+02 -2.16188565e+02  1.51533642e+02\n",
            "   2.16446538e+02  2.69637402e+01 -1.46545255e+02 -3.90093919e+02\n",
            "   2.97305335e+02  1.82847831e+02  8.58302182e+01 -5.33790287e+01\n",
            "  -7.85159984e+01  2.10999175e+02  3.01660226e+02  2.15819598e+02\n",
            "  -1.85075575e+02  8.36084292e+01  3.67352206e+02 -9.44788903e+01\n",
            "   2.91226958e+01  1.67661365e+02 -4.44856436e+02  1.69596756e+02\n",
            "  -7.97716335e+01  1.16131868e+02  1.16872991e+02 -5.61411984e+01\n",
            "  -1.98965193e+02  2.87289302e+02 -1.95851072e+02 -1.02656567e+02\n",
            "  -2.18228012e+02  4.14484025e+02 -1.07274621e+02 -8.26999072e+01\n",
            "  -2.68926821e+00  1.44087296e+02 -2.18003301e+02 -9.15855092e+01\n",
            "  -1.96853687e+02  2.10919230e+00 -1.87062979e+02  3.47850292e+02\n",
            "   5.85599672e+01  3.06883263e+02  4.59585204e+01  1.31132585e+02\n",
            "   5.09066029e+01 -5.88100564e+01  1.00558173e+02  1.65291549e+02\n",
            "  -1.91235251e+02 -3.42876448e+02  1.27399013e+02  1.10552472e+01\n",
            "  -1.72270224e+02 -1.83679135e+01  6.12426336e+01  4.54918975e+00\n",
            "  -2.87161184e+02  6.79971380e+01 -1.06790050e+02 -1.18937273e+02\n",
            "  -4.47451683e+01  1.62653016e+02 -1.80644674e+02  2.04907266e+02\n",
            "  -7.72748014e+00  2.97645017e+02  2.87179223e+00  6.38867896e+01\n",
            "   1.12157295e+02 -3.44594944e+01 -3.24524254e+02 -1.50111340e+02\n",
            "  -1.04678699e+02  2.27852546e+02]\n",
            " [ 2.90370161e+03 -1.13507676e+03  3.13628798e+02  1.02820662e+02\n",
            "   2.71843756e+03 -2.83258514e+02 -9.52768138e+02 -5.34516102e+02\n",
            "  -5.96095073e+02 -8.95716913e+01 -3.07167664e+02 -1.05316062e+02\n",
            "   2.24232073e+02 -1.12120192e+03 -3.29437356e+02 -2.08627428e+02\n",
            "  -4.59775201e+02  1.46847216e+02  1.05497337e+03  5.47773994e+02\n",
            "   2.78977525e+01  1.66200694e+02 -2.29895372e+01  3.21274326e+02\n",
            "   1.42684549e+02 -1.93354919e+02 -1.00642503e+01 -9.78774986e+01\n",
            "  -4.11073877e+01  6.92881743e+00  2.41595747e+02  2.71639656e+02\n",
            "   1.93004744e+02  5.09170932e+02 -5.47925242e+02  5.12482125e+02\n",
            "  -1.10203971e+02  2.96406688e+02  1.37323536e+02 -1.28406137e+02\n",
            "   3.71013456e+02  2.28298146e+02 -1.01140702e+02 -1.94461258e+02\n",
            "   7.49459038e+01  3.81494212e+02  4.12003317e+02  1.03774563e+02\n",
            "  -1.97706495e+02  8.10739861e+01 -2.94785462e+02  1.78726353e+02\n",
            "  -1.41955250e+02 -1.20485677e+02 -3.33597050e+02  6.26738098e+01\n",
            "   1.45930776e+02  1.60851797e+01 -1.24542736e+02 -1.06074774e+02\n",
            "   8.61888919e+01 -2.97615314e+02  2.88066033e+02  1.82368948e+00\n",
            "   3.03207003e+02  3.35467167e+01  1.92813158e+02  2.16259839e+02\n",
            "   1.27939945e+02 -1.56430798e+02 -4.97314706e+01  6.46064983e+01\n",
            "   2.21011052e+02  9.17044381e+01  1.49873189e+02 -1.89536527e+01\n",
            "  -1.42958667e+02  1.60794086e+02  2.74410620e+02 -1.25504794e+02\n",
            "  -1.47501788e+02  7.56906141e+01  5.09143514e+01 -1.56780296e+02\n",
            "   4.99117433e+01  4.97979839e+01  2.23271018e+02  4.73386037e+01\n",
            "  -7.28832635e+01  2.19797524e+02 -1.68138779e+02  2.89796543e+02\n",
            "   4.67990558e-01  1.73756933e+02 -1.12121014e+02 -8.07358836e+01\n",
            "  -4.48275437e+01  1.86775808e+02 -1.68134038e+02  3.13917060e+01\n",
            "  -1.38328315e+02  1.07672887e+02 -7.44143840e+00  1.50776918e+01\n",
            "  -9.45270579e+01 -3.13370788e+01 -1.64718915e+02 -2.83517105e+01\n",
            "  -2.45510963e+02  5.62197474e+01]\n",
            " [ 2.57225743e+03 -8.08304607e+02 -7.95659059e+02  9.78668212e+02\n",
            "   3.07580576e+02 -1.31766977e+03 -2.56193927e+02 -1.19432692e+02\n",
            "  -1.52283830e+03  3.22215666e+02  2.47919996e+02  6.08479068e+02\n",
            "  -1.54858677e+02 -1.42200680e+02 -6.53759642e+02 -3.68912511e+02\n",
            "   1.17790127e+02  4.01491791e+02 -3.61573832e+02  9.72177975e+01\n",
            "   3.07865298e+02  2.48166891e+02 -1.70658078e+02  1.52110472e+02\n",
            "   8.06353287e+01 -7.15533127e+01 -4.99954745e+02  4.84404433e+02\n",
            "   3.09520457e+02 -1.32833261e+02  2.90491532e+02  4.37745667e+02\n",
            "   3.23888871e+02 -5.71632299e+02 -4.18333068e+02 -9.05805477e+01\n",
            "   1.08643521e+02  1.73512249e+02 -4.88431613e+02 -1.70200361e+02\n",
            "   4.99923518e+02 -2.66733090e+02  2.23005800e+02  9.85747939e+00\n",
            "   3.84532218e+02  2.70919586e+01  1.03610681e+02  2.62758651e+02\n",
            "  -4.77257050e+02 -3.44246571e+02 -5.48178009e+01 -4.25527251e+01\n",
            "  -1.80072084e+02  2.18577888e+02 -3.07811573e+02  7.87708598e+01\n",
            "   1.72327582e+01 -1.67573391e+02 -2.21136797e+02  2.05391597e+02\n",
            "   2.75592459e+02 -2.02049304e+02 -3.82271867e+02  4.46545338e+01\n",
            "  -5.14979609e+01 -2.08271812e+02 -6.60139409e+01 -7.15044330e+01\n",
            "   1.10243962e+02  3.11548702e+02  1.08011378e+02  9.78986109e+00\n",
            "   1.12289990e+01  5.46931902e+01  2.27377220e+02  1.89497805e+02\n",
            "  -4.57932055e+01 -4.06274059e+01 -2.70676109e+02  1.81278632e+02\n",
            "  -2.03368128e+02 -2.96625772e+02 -1.01928841e+01 -8.20490868e+01\n",
            "   1.96687172e+02  1.05065789e+02  1.34326745e+02 -3.09092342e+01\n",
            "   7.19884339e+01 -3.07391349e+02  2.84463059e+02 -2.25203417e+01\n",
            "   4.32574240e+01 -6.05493193e+01  5.15866707e+01  6.82603616e+01\n",
            "  -4.66312969e+00 -2.90396150e+02  3.91182154e+01  1.01060901e+02\n",
            "  -2.11511655e+02 -2.06114179e+02 -2.41213801e+02 -1.44688328e+02\n",
            "   2.79119167e+02 -5.53811087e+01  2.15386332e+02  8.13502591e+01\n",
            "   3.37776014e+02  1.50226969e+02]\n",
            " [ 3.09043133e+03 -1.40629798e+03 -3.90822041e+02 -2.15934474e+03\n",
            "   7.85203242e+02 -1.32909323e+03  3.67656157e+02  9.28209039e+02\n",
            "  -1.72735143e+02  1.50634289e+03  8.43016251e+02  2.79565511e+02\n",
            "   7.09676046e+02 -1.68332123e+01  5.20210637e+02  6.43900899e+02\n",
            "   3.45518889e+02  4.53981332e+02 -2.55342447e+02  6.83936248e+02\n",
            "   1.71795552e+02 -2.89067095e+02  1.54337538e+01 -4.54028002e+02\n",
            "   8.35442416e+01 -2.72760811e+02 -2.40258532e+02  1.97405454e+02\n",
            "   1.55121096e+02 -9.74717486e+01 -8.80214174e+01  2.93532722e+02\n",
            "   3.39927459e+02 -4.67315128e+02  4.70789269e+02 -2.93466390e+02\n",
            "  -3.87561619e+02 -1.69849673e-01 -3.23074369e+02  7.01234811e+01\n",
            "  -2.80891196e+02 -2.08176111e+02 -4.04622174e+00  4.28594218e+01\n",
            "  -6.79355549e+01  1.24781108e+02  1.37034609e+02  1.60369214e+02\n",
            "  -1.92583160e+02 -1.10541231e+02  3.62569618e+02 -4.73442875e+01\n",
            "   6.10762303e+01  2.58023293e+02  4.34621531e+02 -3.66906038e+02\n",
            "   1.58473300e+02 -1.43203432e+02  1.27883769e+02  1.90170479e+01\n",
            "   1.96793201e+02  3.49836230e+01 -1.56650475e+02 -3.24192768e+01\n",
            "  -3.02781068e+01  7.76960077e+01 -1.77810635e+02  2.17260883e+02\n",
            "  -1.04251783e+02 -8.20596910e+00  1.34233631e+02 -3.57325361e+01\n",
            "  -1.11444488e+02 -3.67853735e+02  1.00221122e+02 -1.76815054e+02\n",
            "  -2.84437750e+02  1.22402666e+02 -1.73938449e+01 -1.04383567e+02\n",
            "  -1.75138292e+01  4.48197395e+01  2.97075641e+02 -9.56795790e+01\n",
            "   2.33886328e+02  1.88782880e+01 -3.37481031e+01  2.51825053e+02\n",
            "  -3.21251455e+02  1.75757263e+02  8.88011289e+01  3.98156076e+02\n",
            "  -2.02234792e+02 -9.83456869e+01  2.10806160e+02 -1.49743048e+02\n",
            "   2.61455895e+02  1.63391773e+02 -1.57290665e+02 -1.17907152e+01\n",
            "   5.93291941e+01 -8.68649713e+01 -1.04040070e+02 -1.80009561e+02\n",
            "  -2.76625668e+01  4.62914876e+01  5.64101407e+01  1.94678860e+01\n",
            "  -1.70932103e+02 -1.81837596e+02]\n",
            " [ 3.54602885e+03 -1.23685556e+03 -5.53476211e+02 -1.56321294e+03\n",
            "   8.87896631e+02 -8.75074140e+02 -3.12203437e+02 -2.77168716e+02\n",
            "  -3.04763122e+02  2.37603558e+02  3.38446533e+01  1.87205818e+02\n",
            "   3.82363222e+02 -9.70313998e+02  6.71914143e+01  2.53910568e+02\n",
            "  -1.03521973e+02  2.70208979e+02  1.18230620e+03  8.42338907e+02\n",
            "  -3.43560698e+02  2.90173654e+02  4.10077770e+02  1.08862632e+02\n",
            "   4.36748289e+02 -1.83341090e+02 -1.77982142e+02 -2.59726998e+02\n",
            "   3.61432301e+02  6.37650267e+01  2.72467594e+02  3.52622843e+02\n",
            "   7.55271786e+01  4.34681795e+01 -4.38786853e+02  3.60852683e+02\n",
            "  -2.83200741e+02  3.48222702e+02  4.93307990e+02  1.01477226e+02\n",
            "  -8.82904008e+01  1.11355056e+02 -1.09223235e+02  2.36529996e+02\n",
            "  -1.91983912e+02  5.28177092e+02  2.05868695e+02 -5.34272651e+01\n",
            "  -1.23276856e+02  2.18551053e+02 -1.29346512e+02  2.91076481e+02\n",
            "  -4.46939495e+01 -1.33838671e+02 -1.76799046e+02  7.27026595e+01\n",
            "   1.52223593e+02 -5.96916732e+01 -6.95198699e+01 -1.15737600e+02\n",
            "  -6.80177054e+01 -4.05596535e+01  2.44568430e+02 -1.98145433e+02\n",
            "  -1.67140863e+02 -1.79172951e+02  1.16230088e+02  2.05887024e+02\n",
            "  -2.95518978e+01 -1.06167827e+02  2.35668474e+00  2.57383367e+02\n",
            "  -9.07295600e+01  9.98321901e+01  8.84367661e+01  2.19745991e+02\n",
            "  -9.26705641e+01 -9.92306257e+01  5.75948326e+01 -2.77919624e+02\n",
            "  -8.83974337e+01 -1.38702305e+02 -1.05417724e+02 -1.96569332e+02\n",
            "   7.06459302e+01  8.43150758e+01  8.31795746e+01 -6.32606556e+01\n",
            "   8.31154449e+01  1.95339971e+01 -1.64376545e+02 -1.16377855e+02\n",
            "   1.87411969e+02  7.73055274e+01 -2.66819207e+01 -1.02551796e+02\n",
            "   1.17461829e+02  6.41721632e+01  3.69797797e+01 -2.42116627e+02\n",
            "  -1.20682282e+01  9.47364675e+01  9.29753912e+01  1.72945119e+02\n",
            "   4.85940490e+01 -9.22838367e+01  2.80006601e+02  1.40912636e+02\n",
            "   9.98786431e+01  2.78450132e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification Experiment\n",
        "part 3.2"
      ],
      "metadata": {
        "id": "lp2YyeHa5Pjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the distance between two points\n",
        "def dis(x1,x2):\n",
        "  return np.linalg.norm(x1-x2)\n",
        "\n",
        "#classification\n",
        "def myclassifier(Train,Trainlabel,Test):\n",
        "  pred=[]\n",
        "  for testpoint in Test:\n",
        "    pred_dis=[]\n",
        "    for trainpoint in Train:\n",
        "      pred_dis.append(dis(testpoint,trainpoint))\n",
        "    pred.append(Trainlabel[np.argmin(pred_dis)])\n",
        "  return np.array(pred)\n",
        "\n",
        "def calculate_accuracy(true_labels,predicted_labels):\n",
        "  if len(true_labels)!=len(predicted_labels):\n",
        "    raise ValueError(\"Length of true_label must be the same.\")\n",
        "  #count the number of correct predictions\n",
        "  correct_predictions=sum(1 for true, predicted in zip(true_labels,predicted_labels)if true == predicted)\n",
        "  #calculate accuracy as the ratio of correct predictions to total predictions\n",
        "  accuracy=correct_predictions / len(true_labels)\n",
        "  return accuracy\n",
        "\n",
        "#read Train data and Test Data\n",
        "Traindata=pd.read_csv('TrainData.csv')\n",
        "Testdata=pd.read_csv('TestData.csv')\n",
        "\n",
        "#we need to saperate data from labels\n",
        "Y_train=Traindata.iloc[:,-1]#save the label train\n",
        "Train=Traindata.iloc[:,:-1].to_numpy()\n",
        "y_test=Testdata.iloc[:,-1]\n",
        "Test=Testdata.iloc[:,:-1].to_numpy()\n",
        "accuracies=[]\n",
        "for k in range(1,110):\n",
        "  pca=PCA(n_components=k)\n",
        "  pca.fit(Train)\n",
        "  reduced_train=pca.transform(Train)\n",
        "  reduce_test=pca.transform(Test)\n",
        "  pred=myclassifier(reduced_train,Y_train,reduce_test)\n",
        "  accuracy=calculate_accuracy(y_test,pred)\n",
        "  accuracies.append(accuracy*100)\n",
        "accuracies=np.array(accuracies)\n",
        "plt.plot(accuracies)\n",
        "plt.ylim([0,100])\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('percentage %')\n",
        "plt.grid()\n",
        "plt.title('Accuracy Computation plot')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "1e0oVEQ45xDo",
        "outputId": "23a0bb1c-b9da-4099-9c91-e536540df1a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Accuracy Computation plot')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUyElEQVR4nO3deVhU1f8H8PcAwwz7vgoIrqi4ouJWauKSWxZamuaSmSX2daksv6WpWZa/NNNMW1yyMPuaWlZmEppmKe4L5i6KC4uI7DAMM+f3BzI6AsrobFzer+fxeZw7d+585jB635x7zj0yIYQAERERkUTZWLoAIiIiIlNi2CEiIiJJY9ghIiIiSWPYISIiIklj2CEiIiJJY9ghIiIiSWPYISIiIklj2CEiIiJJY9ghIiIiSWPYISKqQf7880/IZDL8+eefli6lSjWhRqpdGHaIDPTZZ59BJpMhKirK0qXUSOnp6XjttdcQHh4OR0dHODk5ITIyEnPnzkV2dralyzOKf/75B7NmzXqoz/PZZ59h9erVRqupptiyZQtmzZpl6TJIYmRcG4vIMJ07d8a1a9dw8eJFnD17Fg0aNLB0STXG/v370bdvX+Tn52PEiBGIjIwEABw4cADr1q1Dp06dsG3bNgtX+fA++ugjvP7660hOTkZoaOgDHSMiIgLe3t4Veke0Wi1KSkpgb28PGxvr/H31zz//RPfu3bFjxw5069bNoNdOnDgRS5cuBU9NZEx2li6AqCZJTk7GP//8g40bN2L8+PGIi4vDO++8Y+myKlVQUAAnJydLl6GTnZ2NJ598Era2tjh8+DDCw8P1nn/vvffw5ZdfWqi6msPGxgZKpdLSZRDVKNb5awGRlYqLi4OHhwf69euHwYMHIy4urtL9srOzMWXKFISGhkKhUCAoKAgjR45EZmambp/i4mLMmjULjRo1glKpREBAAJ566imcP38eQNXjHi5evAiZTKZ3iWP06NFwdnbG+fPn0bdvX7i4uGD48OEAgL/++gtDhgxBSEgIFAoFgoODMWXKFBQVFVWo+9SpU3j66afh4+MDBwcHNG7cGG+99RYAYMeOHZDJZNi0aVOF161duxYymQx79uypsu0+//xzXL16FQsXLqwQdADAz88Pb7/9tt62zz77DM2aNYNCoUBgYCBiY2MrXBrq1q0bIiIicOzYMXTt2hWOjo5o0KABfvjhBwDAzp07ERUVpfs8f/zxh97rZ82aBZlMpvvsrq6u8PLywqRJk1BcXHzPdi8nk8l0l15mzZqF119/HQAQFhYGmUwGmUyGixcvAgBWrVqFxx57DL6+vlAoFGjatCmWLVumd7zQ0FCcOHECO3fu1L2+vIekqu/F+vXrERkZCQcHB3h7e2PEiBG4evWq3j7l35OrV69i0KBBcHZ2ho+PD1577TVoNJoKn+tuoaGh6N+/P7Zt24ZWrVpBqVSiadOm2Lhx431fW50aR48ejaVLl+ratPwP0cNi2CEyQFxcHJ566inY29tj2LBhOHv2LPbv36+3T35+Ph555BEsWbIEvXr1wieffIKXXnoJp06dwpUrVwAAGo0G/fv3x+zZsxEZGYkFCxZg0qRJyMnJQVJS0gPVVlpait69e8PX1xcfffQRYmJiAJSdYAoLC/Hyyy9jyZIl6N27N5YsWYKRI0fqvf7YsWOIiorC9u3bMW7cOHzyyScYNGgQfv75ZwBloSI4OLjSgBcXF4f69eujY8eOVda3efNmODg4YPDgwdX6PLNmzUJsbCwCAwOxYMECxMTE4PPPP0evXr2gVqv19r158yb69++PqKgozJ8/HwqFAkOHDsX333+PoUOHom/fvvjggw9QUFCAwYMHIy8vr8L7Pf300yguLsa8efPQt29fLF68GC+++GK1ar3TU089hWHDhgEAPv74Y3zzzTf45ptv4OPjAwBYtmwZ6tati//+979YsGABgoODMWHCBN1JHgAWLVqEoKAghIeH615fHjors3r1ajz99NOwtbXFvHnzMG7cOGzcuBFdunSpEA41Gg169+4NLy8vfPTRR+jatSsWLFiAL774olqf7+zZs3jmmWfw+OOPY968ebCzs8OQIUMQHx9/z9dVp8bx48ejZ8+eAKD73N9880216iK6J0FE1XLgwAEBQMTHxwshhNBqtSIoKEhMmjRJb7+ZM2cKAGLjxo0VjqHVaoUQQqxcuVIAEAsXLqxynx07dggAYseOHXrPJycnCwBi1apVum2jRo0SAMSbb75Z4XiFhYUVts2bN0/IZDJx6dIl3bZHH31UuLi46G27sx4hhJg+fbpQKBQiOztbty0jI0PY2dmJd955p8L73MnDw0O0bNnynvvceUx7e3vRq1cvodFodNs//fRTAUCsXLlSt61r164CgFi7dq1u26lTpwQAYWNjI/bu3avb/vvvv1dou3feeUcAEAMHDtSrYcKECQKAOHr0qBCi8nYvB0Dv8//f//2fACCSk5Mr7FvZz6N3796iXr16etuaNWsmunbtWmHfu78XJSUlwtfXV0RERIiioiLdfr/88osAIGbOnKnbVv49mTNnjt4xW7duLSIjIyu8193q1q0rAIgNGzbotuXk5IiAgADRunVro9QYGxsreGoiY2PPDlE1xcXFwc/PD927dwdQ1s3+zDPPYN26dXqXADZs2ICWLVviySefrHCM8i75DRs2wNvbG6+88kqV+zyIl19+ucI2BwcH3d8LCgqQmZmJTp06QQiBw4cPAwCuX7+OXbt24fnnn0dISEiV9YwcORIqlUp3iQgAvv/+e5SWlmLEiBH3rC03NxcuLi7V+hx//PEHSkpKMHnyZL1BuOPGjYOrqyt+/fVXvf2dnZ0xdOhQ3ePGjRvD3d0dTZo00Zs1V/73CxcuVHjP2NhYvcflP5stW7ZUq+bquvPnkZOTg8zMTHTt2hUXLlxATk6Owcc7cOAAMjIyMGHCBL2xPP369UN4eHiFtgKAl156Se/xI488UmmbVCYwMFDvu+3q6oqRI0fi8OHDSEtLM1qNRMbEsENUDRqNBuvWrUP37t2RnJyMc+fO4dy5c4iKikJ6ejoSEhJ0+54/fx4RERH3PN758+fRuHFj2NkZb46AnZ0dgoKCKmxPSUnB6NGj4enpqRuj0bVrVwDQnVzLT3T3qzs8PBzt2rXTu5QVFxeHDh063HdWmqura6WXjypz6dIlAGWh5U729vaoV6+e7vlyQUFBFUKim5sbgoODK2wDyi573a1hw4Z6j+vXrw8bGxvdWBtj+fvvvxEdHQ0nJye4u7vDx8cH//3vfwHggcJOVW0FlP287m4rpVKpu6RWzsPDo9I2qUyDBg0qtHWjRo0AoMq2MrRGImPjbCyiati+fTtSU1Oxbt06rFu3rsLzcXFx6NWrl1Hfs6oenqoGkioUigpTkTUaDXr27ImsrCy88cYbCA8Ph5OTE65evYrRo0dDq9UaXNfIkSMxadIkXLlyBSqVCnv37sWnn35639eFh4fjyJEjumnTxmRra2vQdlGNac13t7+hP4/KnD9/Hj169EB4eDgWLlyI4OBg2NvbY8uWLfj4448f6OdhqKrahEjKGHaIqiEuLg6+vr56g0jLbdy4EZs2bcLy5cvh4OCA+vXr33eQcf369ZGYmAi1Wg25XF7pPh4eHgBQYYCpIb8FHz9+HGfOnMHXX3+tNyD57sGk9erVA4BqDY4eOnQopk6diu+++w5FRUWQy+V45pln7vu6AQMGYM+ePdiwYYNuAG9V6tatCwA4ffq0rjYAKCkpQXJyMqKjo+/7foY6e/YswsLCdI/PnTsHrVaru0+OIT+PqoLRzz//DJVKhc2bN+tdLtyxY0e1j3G3O9vqscce03vu9OnTuueN5dy5cxBC6NV35swZAKjynkKG1MjZV2QKvIxFdB9FRUXYuHEj+vfvj8GDB1f4M3HiROTl5WHz5s0AgJiYGBw9erTSKdrlPQoxMTHIzMystEekfJ+6devC1tYWu3bt0nv+s88+q3bt5b/F39mTIYTAJ598orefj48PHn30UaxcuRIpKSmV1lPO29sbjz/+OL799lvExcWhT58+8Pb2vm8tL730EgICAvDqq6/qTo53ysjIwNy5cwEA0dHRsLe3x+LFi/Xef8WKFcjJyUG/fv3u+36GujvILlmyBADw+OOPAyi7DOft7V2tn0f5/Y3uDkaV/TxycnKwatWqSo9RnTswt23bFr6+vli+fDlUKpVu+2+//YaTJ08ava2uXbum993Ozc3FmjVr0KpVK/j7+z90jVW1HdHDYM8O0X1s3rwZeXl5GDhwYKXPd+jQAT4+PoiLi8MzzzyD119/HT/88AOGDBmC559/HpGRkcjKysLmzZuxfPlytGzZEiNHjsSaNWswdepU7Nu3D4888ggKCgrwxx9/YMKECXjiiSfg5uaGIUOGYMmSJZDJZKhfvz5++eUXZGRkVLv28PBw1K9fH6+99hquXr0KV1dXbNiwodLxGYsXL0aXLl3Qpk0bvPjiiwgLC8PFixfx66+/4siRI3r7jhw5UjeF/N13361WLR4eHti0aRP69u2LVq1a6d1B+dChQ/juu+90U9d9fHwwffp0zJ49G3369MHAgQNx+vRpfPbZZ2jXrt19B0M/iOTkZAwcOBB9+vTBnj178O233+LZZ59Fy5Ytdfu88MIL+OCDD/DCCy+gbdu22LVrV6XBrfxzvfXWWxg6dCjkcjkGDBiAXr16wd7eHgMGDMD48eORn5+PL7/8Er6+vkhNTa1wjGXLlmHu3Llo0KABfH19K/SKAIBcLseHH36IMWPGoGvXrhg2bBjS09PxySefIDQ0FFOmTDFqOzVq1Ahjx47F/v374efnh5UrVyI9Pb3SwPYgNZa33X/+8x/07t0btra2eoPPiR6IpaaBEdUUAwYMEEqlUhQUFFS5z+jRo4VcLheZmZlCCCFu3LghJk6cKOrUqSPs7e1FUFCQGDVqlO55IcqmIL/11lsiLCxMyOVy4e/vLwYPHizOnz+v2+f69esiJiZGODo6Cg8PDzF+/HiRlJRU6dRzJyenSmv7999/RXR0tHB2dhbe3t5i3Lhx4ujRo5VOo05KShJPPvmkcHd3F0qlUjRu3FjMmDGjwjFVKpXw8PAQbm5uelOJq+PatWtiypQpolGjRkKpVApHR0cRGRkp3nvvPZGTk6O376effirCw8OFXC4Xfn5+4uWXXxY3b97U26dr166iWbNmFd6nbt26ol+/fhW2AxCxsbG6x+VTz//9918xePBg4eLiIjw8PMTEiRMrfLbCwkIxduxY4ebmJlxcXMTTTz8tMjIyKkw9F0KId999V9SpU0fY2NjoTUPfvHmzaNGihVAqlSI0NFR8+OGHulsR3DlVPS0tTfTr10+4uLgIALpp6FXdkuD7778XrVu3FgqFQnh6eorhw4eLK1eu6O1T1fekvA3up7xNf//9d9GiRQuhUChEeHi4WL9+vd5+D1NjaWmpeOWVV4SPj4+QyWSchk5GwbWxiMhgpaWlCAwMxIABA7BixQpLl/NQZs2ahdmzZ+P69evVuhxXm4WGhiIiIgK//PKLpUshMgjH7BCRwX788Udcv369wl2YiYisEcfsEFG1JSYm4tixY3j33XfRunVr3f16iIisGXt2iKjali1bhpdffhm+vr5Ys2aNpcshIqoWi4adXbt2YcCAAQgMDIRMJsOPP/6o97wQAjNnzkRAQAAcHBwQHR2Ns2fP6u2TlZWF4cOHw9XVFe7u7hg7dizy8/PN+CmIao/Vq1ejtLQUBw4cuO/dlmuKWbNmQQjB8TrVcPHiRY7XoRrJomGnoKAALVu2rPRGbQAwf/58LF68GMuXL0diYiKcnJzQu3dvFBcX6/YZPnw4Tpw4gfj4ePzyyy/YtWvXA61UTERERNJkNbOxZDIZNm3ahEGDBgEo69UJDAzEq6++itdeew1A2c23/Pz8sHr1agwdOhQnT55E06ZNsX//frRt2xYAsHXrVvTt2xdXrlxBYGCgpT4OERERWQmrHaCcnJyMtLQ0vdvCu7m5ISoqCnv27MHQoUOxZ88euLu764IOUHbnVRsbGyQmJla66jQAqFQqvbt4arVaZGVlwcvLi7cqJyIiqiGEEMjLy0NgYGCFtQHvZLVhJy0tDQDg5+ent93Pz0/3XFpaGnx9ffWet7Ozg6enp26fysybNw+zZ882csVERERkCZcvX0ZQUFCVz1tt2DGl6dOnY+rUqbrHOTk5CAkJQXJyMlxcXIz2Pmq1Gjt27ED37t2rXOyRqo/taTxsS+NiexoP29K4pN6eeXl5CAsLu++522rDTvmCcunp6QgICNBtT09PR6tWrXT73L1OUGlpKbKysqpckA4AFAoFFApFhe2enp5wdXU1QvVl1Go1HB0d4eXlJckvmbmxPY2HbWlcbE/jYVsal9Tbs/wz3W8IitXeZycsLAz+/v5ISEjQbcvNzUViYqJuscCOHTsiOzsbBw8e1O2zfft2aLVaREVFmb1mIiIisj4W7dnJz8/HuXPndI+Tk5Nx5MgReHp6IiQkBJMnT8bcuXPRsGFDhIWFYcaMGQgMDNTN2GrSpAn69OmDcePGYfny5VCr1Zg4cSKGDh3KmVhEREQEwMJh58CBA+jevbvucfk4mlGjRmH16tWYNm0aCgoK8OKLLyI7OxtdunTB1q1boVQqda+Ji4vDxIkT0aNHD9jY2CAmJgaLFy82+2chIiIi62TRsNOtWzfc6zY/MpkMc+bMwZw5c6rcx9PTE2vXrjVFeURERCQBVjtmh4iIiMgYGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0hh2iIiISNIYdoiIiEjSGHaIiIhI0uwsXQAREVmfa9lFmLTuMI5fzdHbHurlhI+faYUmAa4VXrNmz0V8tuM8ujT0xtguYZXu8zDOZeRj5d/J+PVYKlSlGt12W5kMT7apg3cGNIPclr/DU0UMO0RENUCBqhQ5ReqHOoajvS3cHe3vu9/J1FyMXrUP6bmqCs+dSsvD08v34PPnItGpgTcAQKsV+GDrKXyx6wIA4IeDV/DDwSvo3MALY7uEIdxfP/T4uCiqDCUarUC2CkjNKYadXSmA2yHnz9PXq6z5270puHSjEMtGRMJZIc1TmxACJRotFHa2li6lxpHmN4KISEI2HrqC/246jmK19qGOYyMDxj1aD2/0DoeNjazSff45l4nx3xxEnqoUDX2dsWhoK7gq5QCAEo0W0zcex77kLIxatQ8fDWmJPhH+eG39Mfx89BoAYPyj9XAluwi/HU/F3+du4O9zNyq8h4+LAiM71MXwDnXh6VQWvnKK1Fi3LwWr/k5GWq4d3jm0q8LrZDIguokfxnQKRbCno277iWs5mPL9Ufx1NhNPL9+D1WPawddV+VBtZW1KSrUYs3ofjl3OwYKnW6JXM39Ll1SjMOwQ0X0JIXD+egF8XBRwc5A/0DGK1RpculGI+j5OsDPSpYbcYjWSruZAiKr3sbORoXWIB+ztHuw9VaUanE3PR9MA1yoDwt1SbhTCwd4WPi6KSp+/WVCCk6m5uLNspdwWrYLdYXvHewgh8Nmf5/F/v58GAMhtZZChejVUpkSjxec7LyA1uxj/N6SFXg+BEAI/HrmKaT8cg1oj0D7ME18+1xZujvo/7zXPt8er64/i12OpmLTuCOr7OOH89QLY2cgwf3ALPNUmCABw5WYhvv7nIjYcuor84lLd6zVC4HqeCgviz+DTHefwVJsgKOxs8L8Dl1FYUnZpygYCtrY2us/qYG+LJ1vXwehOoQj1dqrwuYI9HRHo7oDnV+/Hv6m5ePKzfzBrYDM42pu2ByTU2wl13B1M+h7lPtx6ShccX/r2IGY/EYHnOtS97+suZRWi9OEy8j0JIXDiWm61eh3bhHjAwcQ/k6ow7BBRlVSlGvx05BpW7k7GqbQ8OMhtMaRtEMZ0DkNYJSedymTkFeObPZfw7d5LuFmoRh13B4zpHIqn2wXregwMdelGAVb9fRHrD1xGQYnmvvs3CXDF6jHt4Gfgb/sZucUYvarsBFrP2wljOociJjIIjvYV/+vUCiD+3wys3puCfclZsLORoW/zALzwSBhaBLkDAM6m52Hl38nYeOgqVJWcgYI9HTC6Uxieblv2Hu9sTsK3e1MAAC8+Wg9v9qm6R6Y6fjh4BW9uOIbNR6/hep4Ky5+LhKO9LbYcT8XK3ck4eqVsfE6/FgFYMKQllPKKJyal3BZLhrZGgKsSX+1OxvnrBXBW2GHZiDZ4pKGPbr8gD0e81a8p3urXVO/1JaVabDmeiq92X0DS1Vx8ty9F91xjPxeM6hgC+9SjeKJ/b8jl1f9+tAhyx8aXO2PUqn1IzizAuDUHDG0eg8lkQK+mfhjbpR7ahXpAJnvwn829/H4iDSt2JwMAHmnojb/OZmLGj0m4ll2Eab0bV/m+/9t/GdM2HIOv0hZtOhchzPfB/r1VpqRUi5+PXsOK3cn4NzW3Wq/Z/mpX1PNxNloNhpAJca/fiWqH3NxcuLm5IScnB66uxhtQp1arsWXLFvTt29egf7RUuZrQnjmFavx5JgOdG3jD27nib/XFag3+OJmOmwUlFqjuNo1Gg6QTJxDRrBlsbSv/TSs9V4V1+y8jM79s3IaNrOyEDpT9J98j3A+PNvK+Zz/Dkcs52Hz0KtQaUeEYzgo7DI4MQn2f6oUmABAA/j6XiW3/put6c+q4O8BFWfXvbVezi5BXXIo67g5YPaYdGvq56J7TagX2Xij7bblDPS+9IHEuIw+jVu7H1ewiveO5OcgxtF0wgjxu/0Z/s0CFNX+dRaZKVuFzAkC7UA842tth55nbY06CPR3gdEdoupZdhNxbPSAuCjvU83HC0Ss5kMmAmf2bYkznsGq20r3tOnMdL397EAUlGtTzcUJRiQapOcUAAHs7G4x7JAyv9mxcrVAVl3gJ206kY1qfxmgW6GZQHUII7EvOQlxiCjRagWHtQ9C5gRdKS0sf6t95VkEJZv6UhHMZ+Qa/1hClWqH3Hs3ruOGFR8LQt3lApeOR0nKK8efpDKg19+5miajjhtYhHrrHl7MK0XfxX8grLsULXcLwVr8mWLL9HBbGnwEAPNm6Dj6MaVGh5/Jkai4GLf1bF6p9nO2xakx7RNQx7Od0t6yCEqxNvISv91zC9byy/xuUchuEet3/3/GXI9vqXX40huqevxl2wLBTU1h7e6bcKNT9VmlvZ4MnW9XB2EfC0MjPBZn5Kl3vxg0LBx1DBbgpMapTKIa1C0HStRys2J2M7acyDDpGZF0PvNAlDI828sHmo2U9RWcf8mTUtZEPxnYJwyMNve/5G3XKjUKMXrUPFzIL4Kq0w5cj26J5kBs2HLqKVbuTcSGzAADKem66hCGmTR0kXc3FC1/vR25xKep5O+GzEW2QeCELK/9OxqUbhVW+l5uDHZ6NqotRHUORma/Cit3J+PnoNZTeSj4yGdCziR9eeKRiT0BRiQYbD1/Bit3JuHC9rCZ7Oxt88kwrPN484KHa6m4nruVg9Kr9upOVt7M9nusQiuEdQioN6eZk7f/O71RZT52/a9m/l2fbh8DNUY7jV3KwYvcF/HIsVfc9uJ/WIe54oUs9PBbui6Ff7MHRKzloHeKO/43vqAtS/ztwGdM3HodGK9ClgTeWjWgDl1s9pfmqUgxcshsXMgvQqb4nLqbewLVCGZzsbfHZiEh0beRzr7ev1LmMPKzYfREbD13RfVY/VwVGdiz7rB5O9x/4bgoMOwZg2KkZzN2eWq3A9wcu43Rant72ADclBkcGweuOk8KxK9l4fvV+ZOaXQCm30RtI2jLYHSdTc1Fy6z+IQDclWga7w0Q93tWi1QqkpabCPyCgyt/g7WxsEN3UD49H+Ff4TfX89XysTUxBak5Rpa8t5+Zgj2faBaNVsLvediEEdp3NxE9HrqJYff/LUHfydVFieFSIXg/N/WQVlOCFr/fjUEo27G1t4KiwRXZh2RgDF4UdIAPybvWquDnIUaTWoKRUizYh7vhqVDvdIFqNViDhZDq2HE9FyZ2/oQsBp4JreHtET7g56Y/hSM8txrp9l1Gi0eDptsGoe5/fgLVagZ1nrmPbv2kYHBmMyLoe99z/QV25WYjlO8+jRZA7BrYMrPSSlSXUxP83b+SrsDYxBWv23u7tcJDboqGfM45duT11v3WIOwLcqr6UWqzWYvfZTN13y8neFgUlGrg5yLFl0iMVxgftvNVLV1iiQbi/C1aPaQ8/VwX+s+4Ifj56DQFuSvz4cgfsSPgDm2/44p8LZZdXh7QNMmhG14XMAuy6o1cyoo4rXuhSD32bBzzwWDhjYdgxAMNOzWDO9lSVavRmmNzN3s4GT7Wug+e7hOHqzSJMiDuEIrUGzQJdsWp0O1y+WYiv/krG7yfSdJczWgW7Y2yXMDwe4W+0AboPqjZ+N4vVGvznu8PY9m86ACDE0xFjOodiSNtgAMD6A5ex6u+LSMkq67np1dQPi4e1rlYIqI3taSo1uS1VpRr8fDQVK3Yn4+StcSx2NjL0bxGAsV3qoXnQ/S8hZeQV49u9KYi7oxd4xai26NHEr9L9k66W9dJl5qsQ6KbEwFZ1sHznedjZyPD9+A5oEeiCLVu2ILpXH7z107/48Ujl/6fdT3mv5NguYWgf5mmy8UmGqu75mwOUie6SU6TGi2sOIPHWINPnOtbVja0QEPjrbCaOXcnBuv2XsW7/Zd34jEcaeuvu8eHrqkRkXU9czirEjtMZaBboisi6nhb+ZLWbUm6LZSMisf7AZXg5K/BYuK/ezKcxncMwsmMotp/KwI18FYa0DdZ7nuh+FHa2GBwZhJg2dbDnwg2cv16Ank384H+P3py7+booMbVnI0zoVh+/JaXCVSmvMugAZWN8Nk3ohFGr9uHC9QIs33keADCtT2NE1vWEWl3Wg2lvZ4OFT7dC18Y+OJ9RYNDncrC3Rb/mAZXOhKspGHaI7nAtuwijV+3DmfR8OCvs8Plzkeh868Zp5V7rJXDg0k2s+CsZ2/4t67mJaROED2KaV7jcE+zpiJEdQ834CehebG1kGNo+5J7P92xa9YmFqDpkMhk61fdGp/re99+5Ckq5LZ5sHVStfYM9HbHhpU54Yc0BHLx0E9FNfDHukXoV9rOxkVX7mFLDsEM1woXr+Zi+8Rh8NDI8XsmV13xVKWb+mIR9F7PueRwHuS0GtgzUu5kZUHZ32h8OXsHSHeeQkaeCn6sCq0a3R9PAit2iMpkM7UI90S60rOfm0o1CdG7gZTXdukRU+3g42WPtuCgcvHgTbUOt5zKTtWDYIatXVKLBy98ewun0PAC2kG86gfmDW+p6UTJyizFm9X6cuFa9ez3ceTOzJ1vXQcKpdHyXmKKb9tvQ1xmrn29frZuFBXs6Gn0qJRHRg1DY2eqW8CB9DDtk9WZtPoHT6XlwVdohv1iNTYevITO/BMtGRCItpxijVu7D1ewieDnZ48OYFvCu4q61QFkP0aq/L+L41Rx8ty9F74ZmoV6OeL5LGIZEBlvsLp9ERGR8DDtk1TYeuoLvD1yGTAYsGdoSf+/dh2/Oy/HX2UwMXvYP0nKLkV2oRpi3E1aPaXffab2tgt3xZOs62H/xJr766wL+PHMdbULcMbZLPfQI932ou9MSEZF1Ytghq3U2PQ9vbUoCAEzq0RCd6nsh+7RA3Nh2ePHbwzh16/43rYLdsWJUW7373tyLTCZD+zBPtA/j7CgiotqAYYesQr6qFP+cy9S7w+iiP86gSK1BlwbeeOWxhtBqysbUNK/jho0vd8brPxxFsKcj3n0igpediIioSgw7ZHGXbhRg9Kr9SM6seO8HHxcFPn6mFWxtZNDecaPdEC9HfD++oxmrJCKimophh5BwMh1OCjt0qOdl9vc+ejkbY78uW2bB21mBenfctMpZaYepPRvB5x4DjomIiO6HYacW02oF3ttyEit2JwMA3nw8HOMfrWe2+zPsOJWhW2ahaYArVo9pB1/X6t9plIiIqDoYdmqpYrUGr64/il+Ppeq2ffDbKaRmF2HmgGYmv03+un0peOvHJGi0Qm+ZBSIiImPj2aUWyilUY9w3B7AvOQtyWxn+b3BLZOarMPfXk/h6zyWk5Rbjk6HVWwDRUEIIfPzHWSxOOAug6mUWiIiIjIVhR+JSbhTiv5uOI09VqtuWllOE9FwVXBR2WH7H2k/+bkpM/f4ofj+RjuiFO/Wmcrsq7TA4Mgh9mwc8cDBRa7T478bjWH/wCgDglccaYGrPRrytORERmRTDjsSt2H0Bu89lVtju56rA6jHt0STg9tpP/VsEwttZgRfXHMCVm0W4crNI7zV/nc3EvC2nMKpTKJ5tHwI3R3m16yhQlWJC3CHsPHMdNjLg3UERGB5V98E/GBERUTUx7EiYViuw9UQaAOD13o3R2M8FAGBjA0TW9YSbQ8Ww0qGeF7a/1g1HUrL1tv+bmos1ty5xfbj1FBbGn4bDHZe5bG1k6NTAGy90CUPrEA/ddlWpBpuPXMPynedx/noBlHIbfDqsDaK5sjQREZkJw46EHb6crbtc9cIjYVDYVW8MjrezokIYiW7qh/Fd6+Hno6n46q8LOJWWB7WmVG+fX4+l4tdjqWgT4o7RncNwKbMAX++5hMx8FQDAy8keK0a3Q6tgd6N8PiIioupg2JGw32/16jzWxLfaQedeFHa2GBwZhJg2dXDlZhHUGq3uuZuFany3LwWbj1zDoZRsHEo5rHvO31X5QJe+iIiIjIFhR6KEEPgtqWxaeZ9m/kY9tkwmQ7CnY4XtkXU9MK1PY3y75xI2Hr4Kb2cFxnQOfahBzURERA+LYUeiTlzLxeWsIijlNuja2Mds7+vrosTUXo0xtVdjs70nERHRvfDXbYkqv4TVrZEvHO2ZaYmIqPZi2JGo35LKwk6fCONewiIiIqppGHYk6FxGHs5l5ENuK8NjTXwtXQ4REZFFMexI0NZbvTqdG3jDVcnZT0REVLsx7EhQ+SWsx3kJi4iIyLrDjkajwYwZMxAWFgYHBwfUr18f7777LoQQun2EEJg5cyYCAgLg4OCA6OhonD171oJVW1bKjUKcuJYLGxnQsynDDhERkVWHnQ8//BDLli3Dp59+ipMnT+LDDz/E/PnzsWTJEt0+8+fPx+LFi7F8+XIkJibCyckJvXv3RnFxsQUrt5zye+tEhXnB08newtUQERFZnlXPSf7nn3/wxBNPoF+/fgCA0NBQfPfdd9i3bx+Asl6dRYsW4e2338YTTzwBAFizZg38/Pzw448/YujQoRar3RLyVaX4ancyAKB/ywALV0NERGQdrDrsdOrUCV988QXOnDmDRo0a4ejRo9i9ezcWLlwIAEhOTkZaWhqio6N1r3Fzc0NUVBT27NlTZdhRqVRQqVS6x7m5uQAAtVoNtVpttPrLj2XMY97L0u1ncT1PhRBPBzzRwt9s72su5m5PKWNbGhfb03jYlsYl9fas7uey6rDz5ptvIjc3F+Hh4bC1tYVGo8F7772H4cOHAwDS0soG4vr56S9a6efnp3uuMvPmzcPs2bMrbN+2bRscHSsug/Cw4uPjjX7Mu2WpgK8O2wKQIdo7Hwnbtpr8PS3FHO1ZW7AtjYvtaTxsS+OSansWFhZWaz+rDjv/+9//EBcXh7Vr16JZs2Y4cuQIJk+ejMDAQIwaNeqBjzt9+nRMnTpV9zg3NxfBwcHo1asXXF1djVE6gLLEGR8fj549e0IuN+0U8Knrj0Et0tA+1ANvjmgLmUxm0vezBHO2p9SxLY2L7Wk8bEvjknp7ll+ZuR+rDjuvv/463nzzTd3lqObNm+PSpUuYN28eRo0aBX//stlG6enpCAi4PUYlPT0drVq1qvK4CoUCCoWiwna5XG6SL4OpjlvucMpN/HwsDTIZMHNAM9jbS3tgsqnbszZhWxoX29N42JbGJdX2rO5nsurZWIWFhbCx0S/R1tYWWq0WABAWFgZ/f38kJCTons/NzUViYiI6duxo1lotRQiBub+eBAA81ToIEXXcLFwRERGRdbHqnp0BAwbgvffeQ0hICJo1a4bDhw9j4cKFeP755wEAMpkMkydPxty5c9GwYUOEhYVhxowZCAwMxKBBgyxbvJn8ciwVBy/dhIPcFtP6cKVxIiKiu1l12FmyZAlmzJiBCRMmICMjA4GBgRg/fjxmzpyp22fatGkoKCjAiy++iOzsbHTp0gVbt26FUqm0YOXms3zneQDA+K714OdaOz4zERGRIaw67Li4uGDRokVYtGhRlfvIZDLMmTMHc+bMMV9hViI9txgnruVCJgOe61DX0uUQERFZJases0P3tuvMdQBAizpu8HKuOOCaiIiIGHZqtD9vhZ2ujXwsXAkREZH1YtipoUo1Wuw+mwkA6NqYYYeIiKgqDDs11NErOcgpUsPNQY6WQe6WLoeIiMhqMezUUDtPZwAAujT0hp0tf4xERERV4VmyhtrJ8TpERETVwrBTA93IV+HY1RwAQDeGHSIionti2KmB/jqbCSGAJgGu8OWNBImIiO6JYacGKr+E1Y2zsIiIiO6LYaeG0WqF7maCHK9DRER0fww7NUzStRzcKCiBs8IOkXU9LF0OERGR1WPYqWF2ni7r1encwAtyTjknIiK6L54ta5jbU859LVwJERFRzcCwU4PkFKpxKOUmAODRRt4WroaIiKhmYNipQXafy4RWAA19nRHk4WjpcoiIiGoEhp0aZOeZsiUiOAuLiIio+hh2agghxO3xOry/DhERUbUx7NQQp9LykJ6rgoPcFu1CPS1dDhERUY3BsFNDlPfqdKzvBaXc1sLVEBER1RwMOzVE+f11OF6HiIjIMAw7NUC+qhQHLmUBYNghIiIyFMNODfDPuUyoNQKhXo4I9XaydDlEREQ1CsNODbCTC38SERE9MIYdKyeEwJ+nOeWciIjoQTHsWLnz1wtwNbsI9rY26FDPy9LlEBER1TgMO1au/BJWVD1PONrbWbgaIiKimodhx8r9eZpLRBARET0Mhh0rVlSiQWIyp5wTERE9DIYdK3Y6PQ8lpVp4OyvQwNfZ0uUQERHVSAw7VuzC9XwAQANfJ8hkMgtXQ0REVDMx7Fix5MwCAECYN3t1iIiIHhTDjhW7cL0s7NT34V2TiYiIHhTDjhW7oOvZYdghIiJ6UAw7VkqrFUjOLBuzU8+Hl7GIiIgeFMOOlUrLLUaxWgs7GxmCPBwsXQ4REVGNxbBjpcrH64R4OUJuyx8TERHRg+JZ1EpdKL+ExfE6RERED4Vhx0qV9+xwvA4REdHDYdixUuUzsdizQ0RE9HAYdqxU+UwsTjsnIiJ6OAw7VqhYrcGVm0UAeBmLiIjoYTHsWKGUrEIIAbgo7ODtbG/pcoiIiGo0hh0rVL4AaD0fLgBKRET0sBh2rBCXiSAiIjIehh0rxGnnRERExsOwY4XKL2OxZ4eIiOjhMexYoeTye+z4MOwQERE9LIYdK3OzoAQ3C9UA2LNDRERkDAw7VqZ8cHKAmxKO9nYWroaIiKjmY9ixMndOOyciIqKHx7BjZZI57ZyIiMioGHasjG7auTennRMRERkDw46VuVC+ACgvYxERERkFw44V0WgFLt4oBADUZ88OERGRUTDsWJFr2UUoKdXC3tYGdTwcLF0OERGRJDDsWJHyaed1vRxha8MFQImIiIyBYceKXLwVdkI5E4uIiMhoGHasyMUbnHZORERkbA8cdlJTUzF48GD4+PjA09MTAwYMwIULF4xZW61z6dbg5LpejhauhIiISDoeOOw8//zziIiIwM6dO7F9+3b4+fnh2WefNWZttU55z06oF3t2iIiIjKXaYWfSpEkoKCjQPT537hzeeOMNNG3aFK1atcKkSZNw+vRpkxRZG2i0Apez2LNDRERkbNVeaTIoKAiRkZGYP38+Bg4ciGeeeQZRUVHo27cv1Go1Nm7ciOHDh5uyVkm7ll0EtUbA3tYGAW6cdk5ERGQs1Q47r7/+OgYPHowJEyZg9erVWLJkCaKiovDnn39Co9Fg/vz5GDx4sClrlbTyS1ghnHZORERkVAaN2QkLC8Nvv/2GmJgYdO3aFRcvXsRHH32ERYsWYciQIZDJjH+Svnr1KkaMGAEvLy84ODigefPmOHDggO55IQRmzpyJgIAAODg4IDo6GmfPnjV6HaZWfufkUF7CIiIiMiqDByjfuHEDw4cPx/79+3H48GF07NgRx44dM0VtuHnzJjp37gy5XI7ffvsN//77LxYsWAAPDw/dPvPnz8fixYuxfPlyJCYmwsnJCb1790ZxcbFJajKVS7obCnJwMhERkTFVO+wkJCTAz88PPj4+CAoKwqlTp7By5UrMmzcPw4YNw7Rp01BUVGTU4j788EMEBwdj1apVaN++PcLCwtCrVy/Ur18fQFmvzqJFi/D222/jiSeeQIsWLbBmzRpcu3YNP/74o1FrMTX27BAREZlGtcfsxMbGYtq0aYiNjcXWrVsxefJkJCYmonv37jh06BDmzJmDVq1aGXVG1ubNm9G7d28MGTIEO3fuRJ06dTBhwgSMGzcOAJCcnIy0tDRER0frXuPm5oaoqCjs2bMHQ4cOrfS4KpUKKpVK9zg3NxcAoFaroVarjVZ/+bGqc8yLt1Y7r+OuMGoNUmJIe9K9sS2Ni+1pPGxL45J6e1b3c8mEEKI6O7q5uSExMRHh4eEoLi5G06ZNK9xE8MSJE2jWrJnh1VZBqVQCAKZOnYohQ4Zg//79mDRpEpYvX45Ro0bhn3/+QefOnXHt2jUEBAToXvf0009DJpPh+++/r/S4s2bNwuzZsytsX7t2LRwdzd+zohXA64m2KBUyzGhdCm+l2UsgIiKqcQoLC/Hss88iJycHrq6uVe5X7Z6dgQMHYvDgwRg4cCB2796Nvn37VtjHmEEHALRaLdq2bYv3338fANC6dWskJSXpws6Dmj59OqZOnap7nJubi+DgYPTq1euejWUotVqN+Ph49OzZE3K5vMr9UnOKUbp3F+xsZHj2iT6ws+UqHpWpbnvS/bEtjYvtaTxsS+OSenuWX5m5n2qHnRUrVuDzzz/HqVOnMGLECDz//PMPXFx1BQQEoGnTpnrbmjRpgg0bNgAA/P39AQDp6el6PTvp6elo1apVlcdVKBRQKBQVtsvlcpN8Ge533CvZOQCAEE9HOCgr1kX6TPVzqo3YlsbF9jQetqVxSbU9q/uZqh127O3t8corrzxwQQ+ic+fOFcYAnTlzBnXr1gVQNhXe398fCQkJunCTm5uLxMREvPzyy2at9WFc5JpYREREJlPtsGMJU6ZMQadOnfD+++/j6aefxr59+/DFF1/giy++AADIZDJMnjwZc+fORcOGDREWFoYZM2YgMDAQgwYNsmzxBrh0g9POiYiITMWqw067du2wadMmTJ8+HXPmzEFYWBgWLVqktyzFtGnTUFBQgBdffBHZ2dno0qULtm7dqhvcXBPcXgCUPTtERETGZtVhBwD69++P/v37V/m8TCbDnDlzMGfOHDNWZVyXyi9jebNnh4iIyNg47cfChBB39Oww7BARERnbA4Wd7OxsfPXVV5g+fTqysrIAAIcOHcLVq1eNWlxtkJGnQrFaC1sbGYI8uNo5ERGRsRl8GevYsWOIjo6Gm5sbLl68iHHjxsHT0xMbN25ESkoK1qxZY4o6JSv51ppYQR4OkPP+OkREREZn8Nl16tSpGD16NM6ePas3CLhv377YtWuXUYurDTgTi4iIyLQMDjv79+/H+PHjK2yvU6cO0tLSjFJUbcIFQImIiEzL4LCjUCgqvT3zmTNn4OPjY5SiahP27BAREZmWwWFn4MCBmDNnjm6lUZlMhpSUFLzxxhuIiYkxeoFSdzGTPTtERESmZHDYWbBgAfLz8+Hr64uioiJ07doVDRo0gIuLC9577z1T1ChZQgj27BAREZmYwbOx3NzcEB8fj927d+PYsWPIz89HmzZtEB0dbYr6JC0zvwQFJRrYyIBgT047JyIiMoUHvoNyly5d0KVLF2PWUuuU30ww0N0BCjtbC1dDREQkTQaHncWLF1e6XSaTQalUokGDBnj00Udha8uT9/1czOSdk4mIiEzN4LDz8ccf4/r16ygsLISHhwcA4ObNm3B0dISzszMyMjJQr1497NixA8HBwUYvWEquZhcB4CUsIiIiUzJ4gPL777+Pdu3a4ezZs7hx4wZu3LiBM2fOICoqCp988glSUlLg7++PKVOmmKJeSSlQlQIAXJVyC1dCREQkXQb37Lz99tvYsGED6tevr9vWoEEDfPTRR4iJicGFCxcwf/58TkOvhnyVBgDgaG/1i88TERHVWAb37KSmpqK0tLTC9tLSUt0dlAMDA5GXl/fw1UlcYUlZOzopOL6JiIjIVAwOO927d8f48eNx+PBh3bbDhw/j5ZdfxmOPPQYAOH78OMLCwoxXpUQV3OrZcVKwZ4eIiMhUDA47K1asgKenJyIjI6FQKKBQKNC2bVt4enpixYoVAABnZ2csWLDA6MVKTfmYHUd79uwQERGZisFdCv7+/oiPj8epU6dw5swZAEDjxo3RuHFj3T7du3c3XoUSVn4Zy5k9O0RERCbzwGfZ8PBwhIeHG7OWWqeghAOUiYiITO2BzrJXrlzB5s2bkZKSgpKSEr3nFi5caJTCaoNCFQcoExERmZrBYSchIQEDBw5EvXr1cOrUKURERODixYsQQqBNmzamqFGy8nVhhz07REREpmLwAOXp06fjtddew/Hjx6FUKrFhwwZcvnwZXbt2xZAhQ0xRoyQJIVB46zKWEy9jERERmYzBYefkyZMYOXIkAMDOzg5FRUVwdnbGnDlz8OGHHxq9QKkq0WhRqhUAAEdexiIiIjIZg8OOk5OTbpxOQEAAzp8/r3suMzPTeJVJXPk9dgDAUc6wQ0REZCoGXz/p0KEDdu/ejSZNmqBv37549dVXcfz4cWzcuBEdOnQwRY2SVH6PHaXcBna2BmdOIiIiqiaDw87ChQuRn58PAJg9ezby8/Px/fffo2HDhpyJZQCO1yEiIjIPg8+09erV0/3dyckJy5cvN2pBtUX5TCyO1yEiIjItg6+f1KtXDzdu3KiwPTs7Wy8I0b3pFgFlzw4REZFJGRx2Ll68CI1GU2G7SqXC1atXjVJUbcBFQImIiMyj2mfazZs36/7++++/w83NTfdYo9EgISEBoaGhRi1OyrgIKBERkXlUO+wMGjQIACCTyTBq1Ci95+RyOUJDQ7nSuQG4CCgREZF5VPtMq9VqAQBhYWHYv38/vL29TVZUbcBFQImIiMzD4DNtcnKyKeqodbgIKBERkXk8ULdCQkICEhISkJGRoevxKbdy5UqjFCZ1+RygTEREZBYGn2lnz56NOXPmoG3btggICIBMJjNFXZJ3e+o5e3aIiIhMyeCws3z5cqxevRrPPfecKeqpNThmh4iIyDwMvs9OSUkJOnXqZIpaapUCjtkhIiIyC4PDzgsvvIC1a9eaopZa5XbYYc8OERGRKRl8pi0uLsYXX3yBP/74Ay1atIBcLtd7nouBVg8XAiUiIjIPg8+0x44dQ6tWrQAASUlJes9xsHL18Q7KRERE5mFw2NmxY4cp6qh1Ckp4GYuIiMgcDB6zU+7cuXP4/fffUVRUBAAQQhitqNqgkPfZISIiMguDw86NGzfQo0cPNGrUCH379kVqaioAYOzYsXj11VeNXqAUCSFu9+zwMhYREZFJGRx2pkyZArlcjpSUFDg6Ouq2P/PMM9i6datRi5OqYrUW2lsdYezZISIiMi2Dz7Tbtm3D77//jqCgIL3tDRs2xKVLl4xWmJSV9+oAgIOcPTtERESmZHDPTkFBgV6PTrmsrCwoFAqjFCV15eN1HO1tYWPDGWxERESmZHDYeeSRR7BmzRrdY5lMBq1Wi/nz56N79+5GLU6q8nXTznkJi4iIyNQMPtvOnz8fPXr0wIEDB1BSUoJp06bhxIkTyMrKwt9//22KGiWnfBFQZy4VQUREZHIG9+xERETgzJkz6NKlC5544gkUFBTgqaeewuHDh1G/fn1T1Cg5XASUiIjIfB7obOvm5oa33nrL2LXUGlwElIiIyHwM7tlZtWoV1q9fX2H7+vXr8fXXXxulKKnjIqBERETmY3DYmTdvHry9vSts9/X1xfvvv2+UoqSOi4ASERGZj8FhJyUlBWFhYRW2161bFykpKUYpSuryuQgoERGR2Rgcdnx9fXHs2LEK248ePQovLy+jFCV1hVwElIiIyGwMDjvDhg3Df/7zH+zYsQMajQYajQbbt2/HpEmTMHToUFPUKDkFukVA2bNDRERkagZ3Lbz77ru4ePEievToATu7spdrtVqMHDmSY3aqqYA3FSQiIjIbg862QgikpaVh9erVmDt3Lo4cOQIHBwc0b94cdevWNVWNknN7gDJ7doiIiEzN4LDToEEDnDhxAg0bNkTDhg1NVZekFXDMDhERkdkYNGbHxsYGDRs2xI0bN0xVT61QqBuzw7BDRERkagYPUP7ggw/w+uuvIykpyRT11Aqcek5ERGQ+BnctjBw5EoWFhWjZsiXs7e3h4OCg93xWVpbRipOq2wuBsmeHiIjI1Aw+2y5atMgEZdQuXAiUiIjIfAw+244aNcoUddQqXAiUiIjIfAweswMA58+fx9tvv41hw4YhIyMDAPDbb7/hxIkTRi3ubh988AFkMhkmT56s21ZcXIzY2Fh4eXnB2dkZMTExSE9PN2kdD0OrFbennvMyFhERkckZHHZ27tyJ5s2bIzExERs3bkR+fj6AsuUi3nnnHaMXWG7//v34/PPP0aJFC73tU6ZMwc8//4z169dj586duHbtGp566imT1fGwitQa3d+5ECgREZHpGRx23nzzTcydOxfx8fGwt7fXbX/sscewd+9eoxZXLj8/H8OHD8eXX34JDw8P3facnBysWLECCxcuxGOPPYbIyEisWrUK//zzj8lqeVjll7BkMkApf6CONSIiIjKAwV0Lx48fx9q1ayts9/X1RWZmplGKultsbCz69euH6OhozJ07V7f94MGDUKvViI6O1m0LDw9HSEgI9uzZgw4dOlR6PJVKBZVKpXucm5sLAFCr1VCr1Uaru/xYdx4zp7AYQNm089LSUqO9V21QWXvSg2FbGhfb03jYlsYl9fas7ucyOOy4u7sjNTUVYWFhetsPHz6MOnXqGHq4+1q3bh0OHTqE/fv3V3guLS0N9vb2cHd319vu5+eHtLS0Ko85b948zJ49u8L2bdu2wdHR8aFrvlt8fLzu71cKAMAOdtpSbNmyxejvVRvc2Z70cNiWxsX2NB62pXFJtT0LCwurtZ/BYWfo0KF44403sH79eshkMmi1Wvz999947bXXMHLkSIMLvZfLly9j0qRJiI+Ph1KpNNpxp0+fjqlTp+oe5+bmIjg4GL169YKrq6vR3ketViM+Ph49e/aEXC4HAOy7mAUcOwBPVyf07dvFaO9VG1TWnvRg2JbGxfY0HralcUm9PcuvzNyPwWHn/fffR2xsLIKDg6HRaNC0aVNoNBo8++yzePvttw0u9F4OHjyIjIwMtGnTRrdNo9Fg165d+PTTT/H777+jpKQE2dnZer076enp8Pf3r/K4CoUCCoWiwna5XG6SL8Odxy3RyAAATko7SX7xzMFUP6faiG1pXGxP42FbGpdU27O6n8ngsGNvb48vv/wSM2bMQFJSEvLz89G6dWuTLArao0cPHD9+XG/bmDFjEB4ejjfeeAPBwcGQy+VISEhATEwMAOD06dNISUlBx44djV6PMegWAeVMLCIiIrN44DNuSEgIgoODAQAymcxoBd3JxcUFERERetucnJzg5eWl2z527FhMnToVnp6ecHV1xSuvvIKOHTtWOTjZ0m7fUJBhh4iIyBweaO7zihUrEBERAaVSCaVSiYiICHz11VfGrq1aPv74Y/Tv3x8xMTF49NFH4e/vj40bN1qkluooUJUvFcG7JxMREZmDwd0LM2fOxMKFC3U9KACwZ88eTJkyBSkpKZgzZ47Ri7zTn3/+qfdYqVRi6dKlWLp0qUnf11i4CCgREZF5GXzGXbZsGb788ksMGzZMt23gwIFo0aIFXnnlFZOHnZqOi4ASERGZl8GXsdRqNdq2bVthe2RkJG+SVw1cBJSIiMi8DA47zz33HJYtW1Zh+xdffIHhw4cbpSgpuz1mhz07RERE5vBAZ9wVK1Zg27ZtuhlPiYmJSElJwciRI/Vu1rdw4ULjVCkht8fssGeHiIjIHAwOO0lJSbqb/J0/fx4A4O3tDW9vbyQlJen2M9V09Jou/9ZlLPbsEBERmYfBZ9wdO3aYoo5ao/DWAGWO2SEiIjKPB7rPDj043lSQiIjIvBh2zKx8uQhexiIiIjIPhh0zK1TxMhYREZE5MeyYGRcCJSIiMi+GHTMq1WhRrNYC4JgdIiIic2HYMaNCtUb3dy4ESkREZB4MO2ZUPl7HzkYGhR2bnoiIyBx4xjWj2zOxbHnTRSIiIjNh2DEj3mOHiIjI/Bh2zOj2IqAcr0NERGQuDDtmdHsRUPbsEBERmQvDjhlxEVAiIiLzY9gxIy4CSkREZH4MO2bEAcpERETmx7BjRrcHKDPsEBERmQvDjhkV6tbF4mUsIiIic2HYMSPdIqC8jEVERGQ2DDtmVH4ZiwOUiYiIzIdhx4w49ZyIiMj8GHbMKK9YDQBwdZBbuBIiIqLag2HHjPKKy3p2XJTs2SEiIjIXhh0zKg87rgw7REREZsOwY0a5ty5juSh5GYuIiMhcGHbMRAjBy1hEREQWwLBjJkVqDTRaAQBwZc8OERGR2TDsmEl5r46tjQyOvIMyERGR2TDsmEluUdl4HWeFHWQymYWrISIiqj0Ydswkl+N1iIiILIJhx0x0NxTkeB0iIiKzYtgxE87EIiIisgyGHTO5HXbYs0NERGRODDtmkqu7jMWeHSIiInNi2DGTPN3dkxl2iIiIzIlhx0x062JxxXMiIiKzYtgxEw5QJiIisgyGHTPJ4yKgREREFsGwYya5RezZISIisgSGHTPJ5U0FiYiILIJhx0w4ZoeIiMgyGHbMhGN2iIiILINhxwy0WoF81a2p5+zZISIiMiuGHTMoKNFAK8r+zp4dIiIi82LYMYPyXh25rQxKOZuciIjInHjmNYM7x+vIZDILV0NERFS7MOyYAWdiERERWQ7DjhnkMuwQERFZDMOOGegWAeXgZCIiIrNj2DGDPBV7doiIiCyFYccM8nWXsdizQ0REZG4MO2bAAcpERESWw7BjBrlcKoKIiMhiGHbM4PYAZfbsEBERmRvDjhnkqTgbi4iIyFIYdswgn2N2iIiILIZhxwzyOBuLiIjIYhh2zKB8gLKrA3t2iIiIzI1hxwxu31SQPTtERETmZtVhZ968eWjXrh1cXFzg6+uLQYMG4fTp03r7FBcXIzY2Fl5eXnB2dkZMTAzS09MtVHFFWgEUqDQAOGaHiIjIEqw67OzcuROxsbHYu3cv4uPjoVar0atXLxQUFOj2mTJlCn7++WesX78eO3fuxLVr1/DUU09ZsGp9xZrbf2fYISIiMj+rPvtu3bpV7/Hq1avh6+uLgwcP4tFHH0VOTg5WrFiBtWvX4rHHHgMArFq1Ck2aNMHevXvRoUMHS5Stp6jsChbs7WygsLO1bDFERES1kFWHnbvl5OQAADw9PQEABw8ehFqtRnR0tG6f8PBwhISEYM+ePVWGHZVKBZVKpXucm5sLAFCr1VCr1UarV61W63p2XJV2Rj12bVTefmzHh8e2NC62p/GwLY1L6u1Z3c9VY8KOVqvF5MmT0blzZ0RERAAA0tLSYG9vD3d3d719/fz8kJaWVuWx5s2bh9mzZ1fYvm3bNjg6Ohq17qJbYcemVIUtW7YY9di1VXx8vKVLkAy2pXGxPY2HbWlcUm3PwsLCau1XY8JObGwskpKSsHv37oc+1vTp0zF16lTd49zcXAQHB6NXr15wdXV96OOXU6vVSPr+DwCAv5cb+va1/GW1mkytViM+Ph49e/aEXM6ZbQ+DbWlcbE/jYVsal9Tbs/zKzP3UiLAzceJE/PLLL9i1axeCgoJ02/39/VFSUoLs7Gy93p309HT4+/tXeTyFQgGFQlFhu1wuN/qXobxnx9XBXpJfNEswxc+ptmJbGhfb03jYlsYl1fas7mey6tlYQghMnDgRmzZtwvbt2xEWFqb3fGRkJORyORISEnTbTp8+jZSUFHTs2NHc5VaqfIAybyhIRERkGVZ9Bo6NjcXatWvx008/wcXFRTcOx83NDQ4ODnBzc8PYsWMxdepUeHp6wtXVFa+88go6duxoFTOxgNtTz10U0kvURERENYFVh51ly5YBALp166a3fdWqVRg9ejQA4OOPP4aNjQ1iYmKgUqnQu3dvfPbZZ2autGpFGhkA3mOHiIjIUqz6DCyEuO8+SqUSS5cuxdKlS81QkeFurQHKpSKIiIgsxKrH7EjB7QHKVp0riYiIJIthx8SK2LNDRERkUQw7JlbMMTtEREQWxbBjYuWXsRh2iIiILINhx8TKByi78jIWERGRRTDsmJhugDLDDhERkUUw7JiQWqNFiZZjdoiIiCyJYceE8lWlur87M+wQERFZBMOOCeXdGrDjILeB3JZNTUREZAk8A5tQedjheB0iIiLLYdgxofKww0tYRERElsOwY0LlYYeDk4mIiCyHYceE8lRqAICLgmGHiIjIUhh2TIg9O0RERJbHsGNCt8MOBygTERFZCsOOCbFnh4iIyPIYdkwo79ZNBTlmh4iIyHIYdkyIPTtERESWx7BjQrdvKsiwQ0REZCkMOyZUPvWcNxUkIiKyHIYdE8or4mUsIiIiS2PYMaGYNnXQxU+LOu4Oli6FiIio1mKXgwmNfzQMwfknGXaIiIgsiD07REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaQw7REREJGkMO0RERCRpDDtEREQkaZIJO0uXLkVoaCiUSiWioqKwb98+S5dEREREVkASYef777/H1KlT8c477+DQoUNo2bIlevfujYyMDEuXRkRERBYmibCzcOFCjBs3DmPGjEHTpk2xfPlyODo6YuXKlZYujYiIiCysxoedkpISHDx4ENHR0bptNjY2iI6Oxp49eyxYGREREVkDO0sX8LAyMzOh0Wjg5+ent93Pzw+nTp2q9DUqlQoqlUr3OCcnBwCQlZUFtVpttNrUajUKCwtx48YNyOVyox23tmJ7Gg/b0rjYnsbDtjQuqbdnXl4eAEAIcc/9anzYeRDz5s3D7NmzK2wPCwuzQDVERET0MPLy8uDm5lbl8zU+7Hh7e8PW1hbp6el629PT0+Hv71/pa6ZPn46pU6fqHmu1WmRlZcHLywsymcxoteXm5iI4OBiXL1+Gq6ur0Y5bW7E9jYdtaVxsT+NhWxqX1NtTCIG8vDwEBgbec78aH3bs7e0RGRmJhIQEDBo0CEBZeElISMDEiRMrfY1CoYBCodDb5u7ubrIaXV1dJfklsxS2p/GwLY2L7Wk8bEvjknJ73qtHp1yNDzsAMHXqVIwaNQpt27ZF+/btsWjRIhQUFGDMmDGWLo2IiIgsTBJh55lnnsH169cxc+ZMpKWloVWrVti6dWuFQctERERU+0gi7ADAxIkTq7xsZSkKhQLvvPNOhUtm9GDYnsbDtjQutqfxsC2Ni+1ZRibuN1+LiIiIqAar8TcVJCIiIroXhh0iIiKSNIYdIiIikjSGHSIiIpI0hh0TWrp0KUJDQ6FUKhEVFYV9+/ZZuiSrN2/ePLRr1w4uLi7w9fXFoEGDcPr0ab19iouLERsbCy8vLzg7OyMmJqbCHbSpog8++AAymQyTJ0/WbWNbGubq1asYMWIEvLy84ODggObNm+PAgQO654UQmDlzJgICAuDg4IDo6GicPXvWghVbJ41GgxkzZiAsLAwODg6oX78+3n33Xb31jdiWVdu1axcGDBiAwMBAyGQy/Pjjj3rPV6ftsrKyMHz4cLi6usLd3R1jx45Ffn6+GT+FmQkyiXXr1gl7e3uxcuVKceLECTFu3Djh7u4u0tPTLV2aVevdu7dYtWqVSEpKEkeOHBF9+/YVISEhIj8/X7fPSy+9JIKDg0VCQoI4cOCA6NChg+jUqZMFq7Z++/btE6GhoaJFixZi0qRJuu1sy+rLysoSdevWFaNHjxaJiYniwoUL4vfffxfnzp3T7fPBBx8INzc38eOPP4qjR4+KgQMHirCwMFFUVGTByq3Pe++9J7y8vMQvv/wikpOTxfr164Wzs7P45JNPdPuwLau2ZcsW8dZbb4mNGzcKAGLTpk16z1en7fr06SNatmwp9u7dK/766y/RoEEDMWzYMDN/EvNh2DGR9u3bi9jYWN1jjUYjAgMDxbx58yxYVc2TkZEhAIidO3cKIYTIzs4WcrlcrF+/XrfPyZMnBQCxZ88eS5Vp1fLy8kTDhg1FfHy86Nq1qy7ssC0N88Ybb4guXbpU+bxWqxX+/v7i//7v/3TbsrOzhUKhEN999505Sqwx+vXrJ55//nm9bU899ZQYPny4EIJtaYi7w0512u7ff/8VAMT+/ft1+/z2229CJpOJq1evmq12c+JlLBMoKSnBwYMHER0drdtmY2OD6Oho7Nmzx4KV1Tw5OTkAAE9PTwDAwYMHoVar9do2PDwcISEhbNsqxMbGol+/fnptBrAtDbV582a0bdsWQ4YMga+vL1q3bo0vv/xS93xycjLS0tL02tPNzQ1RUVFsz7t06tQJCQkJOHPmDADg6NGj2L17Nx5//HEAbMuHUZ2227NnD9zd3dG2bVvdPtHR0bCxsUFiYqLZazYHydxB2ZpkZmZCo9FUWK7Cz88Pp06dslBVNY9Wq8XkyZPRuXNnREREAADS0tJgb29fYeFWPz8/pKWlWaBK67Zu3TocOnQI+/fvr/Ac29IwFy5cwLJlyzB16lT897//xf79+/Gf//wH9vb2GDVqlK7NKvt3z/bU9+abbyI3Nxfh4eGwtbWFRqPBe++9h+HDhwMA2/IhVKft0tLS4Ovrq/e8nZ0dPD09Jdu+DDtktWJjY5GUlITdu3dbupQa6fLly5g0aRLi4+OhVCotXU6Np9Vq0bZtW7z//vsAgNatWyMpKQnLly/HqFGjLFxdzfK///0PcXFxWLt2LZo1a4YjR45g8uTJCAwMZFuSSfAylgl4e3vD1ta2wqyW9PR0+Pv7W6iqmmXixIn45ZdfsGPHDgQFBem2+/v7o6SkBNnZ2Xr7s20rOnjwIDIyMtCmTRvY2dnBzs4OO3fuxOLFi2FnZwc/Pz+2pQECAgLQtGlTvW1NmjRBSkoKAOjajP/u7+/111/Hm2++iaFDh6J58+Z47rnnMGXKFMybNw8A2/JhVKft/P39kZGRofd8aWkpsrKyJNu+DDsmYG9vj8jISCQkJOi2abVaJCQkoGPHjhaszPoJITBx4kRs2rQJ27dvR1hYmN7zkZGRkMvlem17+vRppKSksG3v0qNHDxw/fhxHjhzR/Wnbti2GDx+u+zvbsvo6d+5c4TYIZ86cQd26dQEAYWFh8Pf312vP3NxcJCYmsj3vUlhYCBsb/dOPra0ttFotALblw6hO23Xs2BHZ2dk4ePCgbp/t27dDq9UiKirK7DWbhaVHSEvVunXrhEKhEKtXrxb//vuvePHFF4W7u7tIS0uzdGlW7eWXXxZubm7izz//FKmpqbo/hYWFun1eeuklERISIrZv3y4OHDggOnbsKDp27GjBqmuOO2djCcG2NMS+ffuEnZ2deO+998TZs2dFXFyccHR0FN9++61unw8++EC4u7uLn376SRw7dkw88cQTnC5diVGjRok6deropp5v3LhReHt7i2nTpun2YVtWLS8vTxw+fFgcPnxYABALFy4Uhw8fFpcuXRJCVK/t+vTpI1q3bi0SExPF7t27RcOGDTn1nB7MkiVLREhIiLC3txft27cXe/futXRJVg9ApX9WrVql26eoqEhMmDBBeHh4CEdHR/Hkk0+K1NRUyxVdg9wddtiWhvn5559FRESEUCgUIjw8XHzxxRd6z2u1WjFjxgzh5+cnFAqF6NGjhzh9+rSFqrVeubm5YtKkSSIkJEQolUpRr1498dZbbwmVSqXbh21ZtR07dlT6/+SoUaOEENVruxs3bohhw4YJZ2dn4erqKsaMGSPy8vIs8GnMQybEHbesJCIiIpIYjtkhIiIiSWPYISIiIklj2CEiIiJJY9ghIiIiSWPYISIiIklj2CEiIiJJY9ghIiIiSWPYISJJ6tatGyZPnmzpMojICjDsEBERkaQx7BAREZGkMewQUa3w66+/ws3NDXFxcZYuhYjMzM7SBRARmdratWvx0ksvYe3atejfv7+lyyEiM2PPDhFJ2tKlSzFhwgT8/PPPDDpEtRR7dohIsn744QdkZGTg77//Rrt27SxdDhFZCHt2iEiyWrduDR8fH6xcuRJCCEuXQ0QWwrBDRJJVv3597NixAz/99BNeeeUVS5dDRBbCy1hEJGmNGjXCjh070K1bN9jZ2WHRokWWLomIzIxhh4gkr3Hjxti+fTu6desGW1tbLFiwwNIlEZEZyQQvZBMREZGEccwOERERSRrDDhEREUkaww4RERFJGsMOERERSRrDDhEREUkaww4RERFJGsMOERERSRrDDhEREUkaww4RERFJGsMOERERSRrDDhEREUkaww4RERFJ2v8DolLuT0IjlxcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "Principal Component Analysis (PCA) is a linear technique that reduces high-dimensional data to a lower-dimensional space by identifying orthogonal components capturing maximum variance.\n",
        "\n",
        "Kernel Principal Component Analysis (KPCA) extends PCA for non-linear data by mapping it to a higher-dimensional space using a kernel function, enabling effective dimensionality reduction and non-linear pattern capture.\n",
        "\n",
        "In summary, PCA is for linear dimensionality reduction, while KPCA extends this to non-linear data using kernel-based transformations for enhanced analysis."
      ],
      "metadata": {
        "id": "a_z-I1we7Kf_"
      }
    }
  ]
}